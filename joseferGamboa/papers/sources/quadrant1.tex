\documentclass[11pt,draft]{article}
\usepackage[applemac]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `basename #1 .tif`.png}

%\usepackage{curves}
%\usepackage{epic}

\hoffset=-13mm
\setlength{\textwidth}{15cm}
\setlength{\textheight}{20cm}

\parskip=1.2ex


%%%%% Setting

\newenvironment{proof}%
	{\par\noindent{\it Proof.}\nopagebreak\normalsize}% 
	{\hfill\linebreak[2]\hspace*{\fill}$\blacksquare$\\[5pt]}
\newenvironment{proofq}%
	{\par\noindent{\it Proof of Theorem \ref{q}.}\nopagebreak\normalsize}% 
	{\hfill\linebreak[2]\hspace*{\fill}$\blacksquare$\\[5pt]}
\newenvironment{proofmain}%
	{\par\noindent{\it Proof of Theorem \ref{main}.}\nopagebreak\normalsize}%
	{\hfill\linebreak[2]\hspace*{\fill}$\blacksquare$\\[5pt]}
\newenvironment{prooffp}%
	{\par\noindent{\it Proof of Theorem
\ref{fp}.}\nopagebreak\normalsize}%
	{\hfill\linebreak[2]\hspace*{\fill}$\blacksquare$\\[5pt]}
\newenvironment{proof41}%
	{\par\noindent{\it Proof of the theorem
\ref{whitneyimpar}.}\nopagebreak\normalsize}%
	{\hfill\linebreak[2]\hspace*{\fill}$\blacksquare$\\[5pt]}
\newenvironment{proof42}%
	{\par\noindent{\it Proof of the theorem
\ref{whitneypar}.}\nopagebreak\normalsize}%
	{\hfill\linebreak[2]\hspace*{\fill}$\blacksquare$\\[5pt]}
\newenvironment{proof51}%
	{\par\noindent{\it Proof of the theorem
\ref{cotainf}.}\nopagebreak\normalsize}%
	{\hfill\linebreak[2]\hspace*{\fill}$\blacksquare$\\[5pt]}
\newenvironment{proof53}%
	{\par\noindent{\it Proof of the lemma
\ref{approx}.}\nopagebreak\normalsize}%
	{\hfill\linebreak[2]\hspace*{\fill}$\blacksquare$\\[5pt]}
\newenvironment{proof61}%
	{\par\noindent{\it Proof of the theorem
\ref{cotasup}.}\nopagebreak\normalsize}%
	{\hfill\linebreak[2]\hspace*{\fill}$\blacksquare$\\[5pt]}
\newtheorem{thm}{Theorem}[section]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{prodef}[thm]{Proposition and Definition}
\newtheorem{defpro}[thm]{Definition and Proposition}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{defn}[thm]{Definition}
\newtheorem{defns}[thm]{Definitions}
\newtheorem{sremark}[thm]{Remark}
\newtheorem{sremarks}[thm]{Remarks}
\newtheorem{sexamples}[thm]{Examples}
\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\theequation}{\roman{equation}}
\newcommand{\add}{\noindent\addtocounter{thm}{1}}
\newcommand{\example}{\add\noindent{\bf Example \thethm \quad }}
\newcommand{\examples}{\add\noindent{\bf Examples \thethm \quad }}
\newcommand{\remark}{\add\noindent{\bf Remark \thethm \quad }}
\newcommand{\remarks}{\add\noindent{\bf Remarks \thethm \quad }}
\newcommand{\notation}{\add\noindent{\bf Notation \thethm \quad }}
\newcommand{\notations}{\add\noindent{\bf Notations \thethm \quad }}
\newcommand{\notes}[1]{\add\noindent{\bf (\thethm) {#1}}}
\newcommand{\fin}{\hspace*{\fill}$\blacksquare$\\[6pt]}


%%%%% Bbb symbols

\newcommand{\K}{{\mathbb K}} \newcommand{\N}{{\mathbb N}}
\newcommand{\Z}{{\mathbb Z}} \newcommand{\R}{{\mathbb R}}
\newcommand{\Q}{{\mathbb Q}} \newcommand{\C}{{\mathbb C}}
\newcommand{\A}{{\mathbb A}} \newcommand{\F}{{\mathbb F}}
\newcommand{\HH}{{\mathbb H}} \newcommand{\BB}{{\mathbb B}}
\newcommand{\sph}{{\mathbb S}} \newcommand{\D}{{\mathbb D}}
\newcommand{\E}{{\mathbb E}}

%%%%% Cal symbols

\newcommand{\psd}{{\cal P}} \newcommand{\pt}{{\cal P}}
\newcommand{\an}{{\cal O}} \newcommand{\pd}{{\cal P}^+}
\newcommand{\hol}{{\cal H}} \newcommand{\nas}{{\cal N}}
\newcommand{\reg}{{\cal R}} \newcommand{\J}{{\cal J}}
\newcommand{\rat}{{\cal K}} \newcommand{\Cont}{{\cal C}}
\newcommand{\mer}{{\cal M}} \newcommand{\I}{{\cal I}}

%%%%% Frak symbols

\newcommand{\gtp}{{\mathfrak p}} \newcommand{\gtq}{{\mathfrak q}}
\newcommand{\gtm}{{\mathfrak m}} \newcommand{\gtn}{{\mathfrak n}}
\newcommand{\gta}{{\mathfrak a}} \newcommand{\gtb}{{\mathfrak b}}
\newcommand{\gtP}{{\mathfrak P}} \newcommand{\gtQ}{{\mathfrak Q}}
\newcommand{\gtd}{{\mathfrak d}} \newcommand{\M}{{\mathfrak
M}}
\newcommand{\ldg}{{\mathfrak e}}

%%%%% Operator names

\newcommand{\nk}{\operatorname{ker}}
\newcommand{\Reg}{\operatorname{Reg}}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\Hom}{\operatorname{Hom}}
\newcommand{\im}{\operatorname{im}}
\newcommand{\qf}{\operatorname{qf}}
\newcommand{\Adh}{\operatorname{Adh}}
\newcommand{\Sing}{\operatorname{Sing}}
\newcommand{\Int}{\operatorname{Int}}
\newcommand{\dist}{\operatorname{dist}}
\newcommand{\Bd}{\operatorname{Fr}}
\newcommand{\hgt}{\operatorname{ht}}
\newcommand{\sen}{\operatorname{sen}}
\newcommand{\arctg}{\operatorname{arctg}}
\newcommand{\tg}{\operatorname{tg}}
\newcommand{\dif}{\operatorname{d}}
\newcommand{\vol}{\operatorname{vol}}
\newcommand{\Alt}{\operatorname{Alt}}
\newcommand{\supp}{\operatorname{sop}}
\newcommand{\Tr}{\operatorname{Tr}}
\newcommand{\Max}{\operatorname{Max}}
\newcommand{\Spec}{\operatorname{Spec}}
\newcommand{\spr}{\Spec_r}
\newcommand{\tr}{\operatorname{tr}}
\newcommand{\trd}{\operatorname{deg}}
\newcommand{\Id}{\operatorname{I}}
\newcommand{\id}{\operatorname{id}}
\newcommand{\cod}{\operatorname{codim}}
\newcommand{\grad}{\operatorname{deg}}
\newcommand{\dvg}{\operatorname{div}}
\newcommand{\rot}{\operatorname{rot}}
\newcommand{\ord}{\operatorname{ord}}
\newcommand{\h}{\operatorname{h}}
\newcommand{\q}{\operatorname{q}}
\newcommand{\ann}{\operatorname{ann}}
\newcommand{\ceros}{\operatorname{Z}}
\newcommand{\ra}{\operatorname{{\mathfrak X}_{\C}}}
\newcommand{\lng}{\operatorname{long}}
\newcommand{\xa}{\operatorname{{\mathfrak X}_{\R}}}
\newcommand{\Adj}{\operatorname{Adj}}
\newcommand{\Partes}{\operatorname{\mathfrak{P}}}
\newcommand{\m}{\operatorname{mult}}
\newcommand{\mt}{\operatorname{mult_{T}}}
\newcommand{\lnh}{\operatorname{\it l}}
\newcommand{\emb}{\operatorname{emb}}
\newcommand{\mcm}{\operatorname{l.c.m}}
\newcommand{\gen}{\operatorname{L_{\R}}}
\newcommand{\rg}{\operatorname{rk}}
\newcommand{\Zar}{\operatorname{zar}}


%%%%% Typewriter symbols

\newcommand{\x}{{\tt x}} \newcommand{\y}{{\tt y}}
\newcommand{\z}{{\tt z}} \renewcommand{\t}{{\tt t}}
\newcommand{\s}{{\tt s}}

%%%%% Varia

\newcommand{\G}{\varGamma} \newcommand{\sos}{{\varSigma_2}}
\newcommand{\Sos}{{\varSigma}} \newcommand{\sosp}{{\varSigma_p}}
\newcommand{\sosq}{{\varSigma_q}}
\newcommand{\veps}{\varepsilon}
\newcommand{\sosm}{{\varSigma_{2m}}}
\newcommand{\sosk}{{\varSigma_k}}
\newcommand{\thalf}{\tfrac{1}{2}}
\newcommand{\half}{\frac{1}{2}}
\newcommand{\ol}{\overline}
\newcommand{\qq}[1]{\langle{#1}\rangle}
\newcommand{\QQ}[1]{\Big\langle{#1}\Big\rangle}
\newcommand{\pp}[1]{\langle\!\langle{#1}\rangle\!\rangle}
\newcommand{\pa}[1]{p[{#1}]}
\newcommand{\pc}[1]{p({#1})}
\newcommand{\e}[1]{E\left[{#1}\right]}
\newcommand{\cf}[1]{qf({#1})}

\begin{document}
\title{\Large \bf Polynomial images of $R^n$}
\author{Jos\'e F. Fernando\footnote{Partially supported by DGICYT,
PB98-0756-C02-01}, J.M. Gamboa\footnote{Partially supported by DGICYT,
PB98-0756-C02-01\hfil\break
\indent\em Keywords\em: polynomial images, real closed field, semialgebraic set,
quadrant.\hfil\break
\indent\em Mathematical Subjet Classification\em: 14P10, 14Q99.}}
\maketitle
\date


\begin{abstract}
Let $R$ be a real closed field and $n\geq 2$. We prove that: (1) for every finite subset $F$ of $R^n$,
the semialgebraic set $R^n\setminus F$ is a polynomial image of $R^n$; and (2) for any
independent linear forms $l_1,\ldots,l_r$ of $R^n$, the semialgebraic set
$\{l_1>0,\ldots,l_r>0\}\subset R^n$ is a polynomial image of $R^n$.
\end{abstract}

\section{Introduction}

Let $R$ be a real closed field and $m,n$ be positive integers. A map
$f=(f_1,\ldots,f_n): R^m\rightarrow R^n$ is said to be \em polynomial \em if the functions $f_i\in
R[x_1,\ldots,x_m]$. 

A celebrated Theorem of Tarski-Seidenberg (\cite[1.4]{bcr}) says that the image of any
polynomial map $f:R^m\rightarrow R^n$ is a semialgebraic subset of $R^n$, i.e. it
can be written as a finite union of subsets defined by a finite conjunction of polynomial
equalities and inequalities. We study some kind of converse of this result.

In an \em Oberwolfach \em week (\cite{g}), the second author proposed to 
characterize the semialgebraic sets of $R^n$ which are polynomial images of $R^m$. In
particular, the open ones deserve a special attention, in connection with the real Jacobian
Conjecture (\cite{p}).

First of all, we introduce some notation and terminology. Let $S$ be a semialgebraic subset 
of $R^n$. We define the \em exterior boundary $\delta S$ \em of $S$ by $\delta
S=\ol{S}\setminus S$ where $\ol{S}$ denotes the closure of $S$ in $R^n$ with respect to the
usual topology. We will denote by $\ol{S}^{\Zar}$ the closure of $S$ in $R^n$ with respect
to the Zariski topology. We say that a subset $A$ of $R^n$ is \em irreducible \em if its
Zariski closure is an irreducible algebraic set.

Now we show some necessary conditions for a subset $S\subset R^n$ to be a polynomial
image of $R^m$. For $m=n=1$ the problem is trivial: \em the images of polynomial maps $R\rightarrow R$ are
singletons, unbounded closed intervals and the whole $R$\em. In the general case, by Tarski-Seidenberg Theorem
(\cite{bcr}),
$S$ is semialgebraic and semialgebraically connected. Moreover, $S$ is irreducible and pure dimensional; this
is an easy consequence of the identity principle for polynomials.

This problem can be also stated in other contexts: regular, Nash, analytic,\ldots. In fact,
Shiota (private communication) has proved the following result:
\begin{thm}\em (Shiota) \em\label{sh}
An irreducible, semialgebraic, connected and pure m-dimensional subset $X\subset\R^n$ is the
image of $\R^m$ for some Nash map $f:\R^m\rightarrow\R^n$ if and only if there
exists a Nash curve $\alpha:\R\rightarrow X$ which meets each connected component of the
regular locus of $X$.
\end{thm}

As we will see immediately, some extra constrains appear in the polynomial case.
Following Jelonek (\cite{j}) and Delfs-Knebush (\cite[\S 9]{dk}), we recall that a 
polynomial map
$f:R^m\rightarrow R^n$ is
\em semialgebraically proper at a point
$p\in R^n$ \em if there exists an open neighborhood $K$ of $p$ in $R^n$ such that the
restriction 
\begin{equation*}
\begin{array}{rcl}
f^{-1}(K)&\rightarrow& K\\
 x\ \ \ &\mapsto& f(x)
\end{array}
\end{equation*}
is a semialgebraically proper map. We denote by ${\mathcal S}_f$ the set of points $p\in
R^n$ at which $f$ is not semialgebraically proper. A \em parametric
semiline of $R^n$
\em is a non-constant polynomial image of $R$; it is semialgebraically closed since every
polynomial map $R \rightarrow R^n$ is semialgebraically proper (\cite{gu}). For dimension
2, Jelonek proves:
\begin{thm}\label{j}
\em (\cite{j})\  \em Let $f:R^2\rightarrow R^2$ be a dominant polynomial map. Then
${\mathcal S}_f$ is a finite union of parametric semilines.
\end{thm}

As easy consequences of this we state
\begin{sremarks}\label{proj}
\em 
Let $f:R^m\rightarrow R^n$ be a polynomial map and $S=f(R^m)$. Then:

\em (1) \em $\delta S\subset{\mathcal S}_f$.  If $p\in\delta S\setminus {\mathcal S}_f$,
then there exists an open neighbourhood $K$ of $p$ such that the restriction 
$f^{-1}(K)\rightarrow K$ of $f$ is proper, and so its image $K\cap S$ is a closed subset of
$K$. Hence, $p\in K\cap \ol S=K\cap\ol{K\cap S}=K\cap S$, a contradiction.

\em (2) \em Suppose $m=n=2$, and let $\Gamma$ be a one dimensional irreducible component of
$\ol{\delta S}^{\Zar}$. Then $\Gamma$ is the Zariski closure of a parametric semiline of
$R^2$. Indeed, $f$ is a dominant map, and so, by \ref{j}, ${\mathcal S}_f$
is a finite union of parametric semilines $M_1,\ldots,M_s$ of $R^2$. Therefore,
$\Gamma\subset \ol{\delta S}^{\Zar}\subset\ol{{\mathcal S}_f}^{\Zar}=
\ol{M_1}^{\Zar}\cup\cdots\cup\ol{M_s}^{\Zar}$, and since $\Gamma$ and the
$\ol{M_i}^{\Zar}$'s are irreducible, we deduce $\Gamma=\ol{M_i}^{\Zar}$ for some $i$.

\em (3) \em Let $S\subset R^n$ be a polynomial image of $R^m$ and $p:R^n\rightarrow R$ be a
polynomial function which is non constant on $S$. Then $p(S)\subset R$ is unbounded. 

Indeed, if $S=f(R^m)$ for some polynomial map $f:R^m\rightarrow R^n$, then for each point
$a\in R^m$, $p(S)$ would contain the image $\varphi_a(R)$ of the polynomial map
$\varphi_a(t)=p(f(ta))$. If $\varphi_a(R)$ were bounded for all $a$ then, for each $a$,
$\varphi_a(R)$ would be a point, say $r_a$. Therefore, given two points $a,b\in R^m$ we
would have
$$ 
p(f(a))=r_a=\varphi_a(0)=\varphi_b(0)=r_b=p(f(b)),
$$
and so, $p$ would be constant on $S$, a contradiction.

Thus all linear projections of $S$ are either a point or unbounded. In particular $S$ is
also unbounded or it is a point.
\em
\end{sremarks}

The first examples one tries to realize as polynomial images are semialgebraic subsets of
$R^2$: 

\begin{sexamples}\label{examples}
\em
\em (i) \em The exterior $S=\{u^2+v^2>1\}$ of the closed unit disc is not a polynomial
image of $R^2$, since the only irreducible component of its exterior boundary is the unit
circle which, being bounded, is not a parametric semiline.  

\em (ii) \em None of the sets $S_1=\{uv<1\}$ and $S_2=\{u>0,uv>1\}$ is a polynomial image
of $R^2$, because the common Zariski closure of their exterior boundaries is the hyperbola
$uv=1$ which is not a parametric semiline.

\em (iii) \em  The punctured plane $S=R^2\setminus\{(0,0)\}$ is the image of the polynomial
map:
$$(x,y)\mapsto (xy-1,(xy-1)x^2-y).$$

\em (iv) \em The open half-planes are polynomial images of $R^2$. For, it suffices to
verify that the upper half plane $\HH: v>0$ is the image of the polynomial map
$$
(x,y)\mapsto (y(xy-1),(xy-1)^2+x^2).
$$
Probably, this is the simplest polynomial map whose image is $\HH$.

\em
\end{sexamples}

In fact, our main results are generalizations of the two last examples above:

\begin{thm}\label{fp}
Let $n\geq 2$. For every finite subset $F$ of $R^n$, the semialgebraic set $R^n\setminus F$ is a 
polynomial image of $R^n$.
\end{thm}


\begin{thm}\label{main}
Let $n\geq 2$. For any independent linear forms $l_1,\ldots,l_r$ of $R^n$, the open semialgebraic set
$\{l_1>0,\ldots,l_r>0\}\subset R^n$ is a polynomial image of $R^n$.\end{thm}


Until now, the known open sets which are polynomial images of $R^2$ (see for instance
\cite{r}) have irreducible exterior boundary and they are \em deformations \em of the open
upper half-plane $\{y>0\}$. In $\cite{r}$ and $\cite{g}$, the authors outline the problem of
finding out whether or not the open quadrant  $Q=\{x>0,y>0\}$ is a polynomial image of
$R^2$; note that the exterior boundary of $Q$ is not irreducible. This is a crucial
particular case of
\ref{main}. The best known approach to the solution of the problem was given by the double
quadratic transform
$$(x,y)\mapsto (x^4 y^2,x^2 y^4)$$  
whose image is $Q\cup\{(0,0)\}$. In section 3 we will prove that in fact:

\begin{thm}\label{q}
The quadrant $Q$ is a polynomial image of $R^2$.
\end{thm} 

The proof consists of two parts. The first one is the choice of a good candidate
to have the quadrant as image. In Section 3 we will give enlighting arguments to
explain the reason of our choice. The second one is devoted to check that
actually the image of the chosen map is the open quadrant. After some
preparation the question is reduced to prove the non existence of real roots of
some univariate polynomials on certain intervals, and to
compare some rational functions on those intervals. Due to the high degree of
the involved polynomials we have used a package which performs the Sturm
algorithm (\cite[1.2.10]{bcr}).

The particular case of the quadrant is the key to prove Theorem \ref{main}: 

\begin{proofmain}
It is clear that after a linear change of coordinates we can suppose that $l_1=x_1,\ldots,l_r=x_r$ 
and then, we only have to prove that
for every pair of positive integers $r\leq n$ the semialgebraic set 
$\{x_1>0,\ldots,x_r>0\}\subset R^n$ is a polynomial image of $ R^n$. It is not difficult to
see that this reduces to prove that:
\begin{itemize}
\item [\em (a) \em] $\HH=\{x_1>0\}$ and $Q=\{x_1>0,x_2>0\}\subset R^2$ are polynomial images
of $R^2$, which is true by \ref{examples} \em (iv) \em and \ref{q}.
\item [\em (b) \em] $O=\{x_1>0,x_2>0,x_3>0\}\subset R^3$ is a polynomial image of $R^3$. 
To show this, we proceed as follows: let $H_1,H_2:R^2\rightarrow R^2$ be polynomial maps
whose respective images are $\HH$ and $Q$. Now consider the maps:
$$
\begin{array}{lrcr}
(H_1,\id_R):& R^3=R^2\times R&\rightarrow& R^3= R^2\times R\\
(\id_R,H_2):& R^3=R\times R^2&\rightarrow& R^3= R\times R^2.
\end{array}
$$
Then, $O$ is the image of the map 
$H=(\id_R,H_2)\circ(H_1,\id_R):R^3\rightarrow R^3$.
\end{itemize}
\end{proofmain}

The proofs of Theorems \ref{fp} and \ref{q} are written just in the case that $R=\R$ is the
field of real numbers. For both of them explicit polynomial maps with the prescribed image
are found. Hence, the usual transfer trick (to see the coefficients of the involved
polynomials as new variables, \cite{bcr}) extends the results to arbitrary $R$.

Most of the computations involved in the elaboration of this paper has been performed by
Maple. The authors thank M.E. Alonso, F.J. Cirre and J.M. Ruiz for helpful
discussions during the preparation of this work. 

\section{Complementary set of a finite set}
The purpose of this section is to prove Theorem \ref{fp}.
\begin{prooffp}
Let $F=\{p_1,\ldots,p_k\}$. We can assume that each $p_j=(a_j,\vec{0})\in\R\times\R^{n-1}$ 
for some $a_j\in\R$.

Indeed, after a linear change of coordinates we have 
$p_j=(a_{1j},\ldots,a_{nj})$ such that $a_{1j}\neq a_{1l}$ if $j\neq l$. Then,
there exists a polynomial $P_1\in\R[T]$ such that $P_1(a_{1j})=a_{nj}$, and so, if
$x'=(x_1,\ldots,x_{n-1})$, the polynomial map 
$$
h_1:\R^n\rightarrow\R^n:\ \ (x',x_n)\mapsto (x',x_n+P_1(x_1))
$$
is bijective and for $p_j'=(a_{1j},\ldots,a_{(n-1)j},0)$ it holds $h_1(p_j')=p_j$. 
Analogously, let $P_2\in\R[T]$ be such that $P_2(a_{1j})=a_{(n-1)j}$, and
$p_j''=(a_{1j},\ldots,a_{(n-2)j},0,0)$. Then, the polynomial bijection
$$
h_2:\R^n\rightarrow\R^n:\ \ (x'',x_{n-1},x_n)\mapsto (x'',x_{n-1}+P_2(x_1),x_n),
$$
where $x''=(x_1,\ldots,x_{n-2})$, satisties $h_2(p_j'')=p_j'$. Thus, the polynomial
bijection $h_1\circ h_2$ maps $p_j''$ to $p_j$. In this way we construct,
inductively, a polynomial bijection $h:\R^n\rightarrow\R^n$ such that $h(q_j)=p_j$ for
$q_j=(a_{1j},\vec{0})$.  Therefore, if $G=\{q_1,\ldots,q_k\}$ and $g:\R^n\rightarrow\R^n$ is
a polynomial map such that $g(\R^n)=\R^n\setminus G$, then $h\circ g(\R^n)=\R^n\setminus F$.
So, in what follows we suppose that $p_j=(a_j,\vec{0})$.

Now, let $r$ be an integer such that $r\neq a_1-a_j$ for $j=1,\ldots,k$,
$\sigma(x)=\sum_{j=3}^n x_j^2$ and 
$$
\rho(x)=\prod_{j=1}^k(x_1x_2-r+a_1-a_j).$$

We claim that the image of the polynomial map $f=(f_1,\ldots,f_n)$ given by:
$$
f(x)=\left(x_1x_2-r+a_1,x_1^{4}\rho(x)+x_1^{2}\sigma(x)+x_2,x_3,\ldots,x_n\right)
$$
is $\R^n\setminus F$.

Indeed, suppose first that there exists $b=(b_{1},\ldots,b_{n})\in\R^n$ such that 
$f(b)=p_\ell$ for some $\ell=1,\ldots,k$. Then $f_1(b)=b_1b_2-r+a_1=a_\ell$ and $f_i(b)=0$
for $i=2,\ldots,n$, and therefore $\rho(b)=0$ and $\sigma(b)=0$; hence $b_2=0$ and
$r=a_1-a_\ell$, which is impossible. So $\im(f)\subset \R^n\setminus F$. Conversely, let
$u=(u_1,\ldots,u_n)\in\R^n\setminus F$. We have to solve the system of polynomial equations:
$$
\begin{array}{rcl}
f_1(x)&=&x_1x_2-r+a_1=u_1\\
f_2(x)&=&x_1^{4}\rho(x)+x_1^{2}\sigma(x)+x_2=u_2\\
f_j(x)&=&x_j=u_j,\ \ \ j\geq 3.
\end{array}
$$
If $u_1=a_1-r$ then $f(0,u_2,\ldots,u_n)=u$. If $u_1\neq a_1-r$, substituting 
$x_2=\frac{u_1-a_1+r}{x_1},x_j=u_j$ for $j\geq 3$ in $f_2$, we  see that $x_1$ must be a
nonzero root of the polynomial
$$
Q(T)=\prod_{j=1}^k(u_1-a_j)T^{5}+\sigma(u)T^{3}-u_2T+(r-a_1+u_1)
$$
which has odd degree (because $u\not\in F$) and $Q(0)=r-a_1+u_1\neq 0$. Then, if 
$b_1$ is a real root of $Q$ we have that
$$
f\left(b_1,\frac{u_1-a_1+r}{b_1},u_3,\ldots,u_n\right)=u.
$$


\end{prooffp}

\section{The Quadrant}

Before entering into the proof of \ref{q}, we must point out that a main difference between
polynomials in one or two variables is that the open interval $(0,+\infty)$ is a polynomial
image of $\R^2$ but not of $\R$. In fact, $(0,+\infty)$ is the image of
$\R^2$ by $f(x,y)=(xy-1)^2+x^2$. However, this polynomial is not useful to obtain
$Q$ as we see immediately.

\begin{sremark}\em
There is not a polynomial map
$$f=(P_1,P_2):\R^2\rightarrow\R^2$$
such that $f(\R^2)=Q$ and $P_1(x,y)=(xy-1)^2+x^2$.

Otherwise, since for each $\lambda\geq 0$ the point $(\lambda^2,0)\in\ol{Q}$, the Curve 
Selection Lemma (\cite[VIII.2.6]{abr}) gives an analytic half-branch curve
$\gamma_\lambda:(0,\delta_\lambda)\rightarrow \R^2$ such that
$$
\lim_{t\rightarrow 0} P_1(\gamma_{\lambda}(t))=\lambda^2 \qquad \text{and} \qquad 
\lim_{t\rightarrow 0} P_2(\gamma_{\lambda}(t))=0.
$$
We can write $\gamma_{\lambda}(t)=(t^{n_{\lambda}}u_{\lambda}(t),t^{m_{\lambda}}
v_{\lambda}(t))$ for some $n_{\lambda},m_{\lambda}\in\Z$ and some units
$u_{\lambda},v_{\lambda}$ in the ring $\R\{t\}$ of power series in one variable,
and 
$$
P_1(\gamma_{\lambda}(t))=\lambda^2+t\xi_{\lambda}(t)
$$
where $\xi_{\lambda}\in\R\{t\}$. Therefore,
$$
\lambda^2+t\xi(t)=(t^{n_{\lambda}+m_{\lambda}}u_{\lambda}(t)v_{\lambda}(t)-1)^2+t^{2n_{\lambda}}u_{\lambda}^2(t),
$$
and since $(\lambda^2,0)\not\in Q$, taking orders with respect to $t$ in the previous 
expression, it is not difficult to deduce that $n_{\lambda}>0$ and
$m_{\lambda}=-n_{\lambda}$. Hence we can reparametrize $\gamma_{\lambda}$ as 
$$
\gamma_{\lambda}(s)=(\varepsilon_{\lambda}s^{n_{\lambda}},s^{-n_{\lambda}}\eta_{\lambda}(s))
$$
for some unit $\eta_{\lambda}\in\R\{s\}$ and $\epsilon_{\lambda}=\pm 1$. Now,
$$P_1(\gamma_{\lambda}(s))=(\varepsilon_{\lambda}\eta_{\lambda}(s)-1)^2+s^{2n_\lambda} $$
and so, 
$\lambda^2=\lim_{s\rightarrow 0}
P_1(\gamma_{\lambda}(s))=(\varepsilon_{\lambda}\eta_{\lambda}(0)-1)^2$. Without loose of
generality we can assume that $\varepsilon_{\lambda}=1$ and
$\eta_{\lambda}(0)=1+\lambda$ for infinitely many values of
$\lambda$. Let us write
$$
P_2(x,y)=\sum_{0\leq i+j\leq d} a_{ij}x^iy^j.
$$
After substituting, for these $\lambda$'s,
$$
P_2(\gamma_{\lambda}(s))=\sum_{0\leq i+j\leq d}
a_{ij}\eta_{\lambda}^js^{(i-j)n_{\lambda}}=\sum_{-l\leq i-j\leq r}
a_{ij}\eta_{\lambda}^js^{(i-j)n_{\lambda}}
$$
where $l\geq 0$ because $a_{00}=P_2(0,0)>0$. Now, since $\lim_{s\rightarrow
0}P_2(\gamma_{\lambda}(s))=0$ and $\eta_{\lambda}(0)=1+\lambda$, it follows, step by step,
that for each $0\leq k\leq l$
$$
\sum_{i-j=-k}a_{ij}(1+\lambda)^j=0
$$
for infinitely many $\lambda$'s, and so each $a_{i,i+k}=0$. In particular, for $k=0$ we get 
$a_{00}=0$, a contradiction.
\fin
\em
\end{sremark} 

Let us now look for a polynomial map $\Phi:\R^2\rightarrow\R^2$ that satisfies
$\Phi(\R^2)=Q$. The major difficulty to find such a map is to get that: 

\begin{itemize}
\item[ ] \em The closure of its image contains the positive half-axes\em. ($\ast$) 
\end{itemize}

Using Theorem \ref{fp}, to realize $Q$ as a polynomial image of $\R^2$ it is enough to find a
polynomial map $P=(F,G):\R^2\rightarrow\R^2$ such that $P(\R^2)$ is the disjoint union of $Q$
and a set of finite preimage.

If such a $P$ exists it also must satisfy $(\ast)$. Then for every non negative numbers
$\lambda,\mu$ there will exist analytic half-branch curve germs
$\alpha_{\lambda}(s),\beta_{\mu}(s)$ which can not be extended to $0$ and such that
$$
\lim_{s\rightarrow 0} P(\alpha_{\lambda}(s))=(\lambda^2,0)\qquad \text{and} \qquad
\lim_{s\rightarrow 0} P(\beta_{\mu}(s))=(0,\mu^2).
$$

We can try parametrizations of the kind
$$
\alpha_{\lambda}(s)=\left(s^{n_{\lambda}},\frac{a_{\lambda 0}+a_{\lambda 1}s+\cdots}{s^{m_{\lambda}}}\right)\qquad \text{and} \qquad
\beta_{\mu}(s)=\left(\frac{b_{\mu 0}+b_{\mu 1}s+\cdots}{s^{\ell_{\mu}}},s^{k_{\mu}}\right).
$$
and as remarked above, it is not difficult to see that 
$a_{\lambda 0},b_{\mu 0}$ must be constants (except maybe for finitely many values of
$\lambda$, $\mu$). In view of this, we will take curves of the type:
$$
\alpha_{\lambda}(s)=\left(s^{n_{\lambda}},\frac{1+a_{\lambda 1}s+\cdots}{s^{m_{\lambda}}}\right)\qquad \text{and} \qquad
\beta_{\mu}(s)=\left(\frac{1+b_{\mu 1}s+\cdots}{s^{\ell_{\mu}}},s^{k_{\mu}}\right),
$$
and in fact we choose the simplest ones, namely 
$$
\alpha_{\lambda}(s)=\left(s,\frac{1+a_{\lambda }s}{s}\right)\qquad \text{and} \qquad
\beta_{\mu}(s)=\left(\frac{1+b_{\mu }s}{s},s^{3}\right).
$$

The following pair of polynomials
\begin{equation*}
\begin{split}
&F=(1-x^3y+y-xy^2)^2+(x^2y)^2=F_1^2+F_2^2\\
&G=(1-xy+x-x^4y)^2+(x^2y)^2=G_1^2+G_2^2
\end{split}
\end{equation*}
have a good behaviour along these curves in the following sense:
\begin{itemize}
\item [\em (a)\em] $F_1\circ\alpha_{\lambda }\in\R[s,a_{\lambda
}],F_1\circ\beta_{\mu}\in\R[s,b_{\mu}]$,
$F_1\circ\alpha_{\lambda }(0)=1-a_{\lambda }$ and $F_1\circ\beta_{\mu}(0)=0$,
\item [\em (b)\em] $G_1\circ\alpha_{\lambda }\in\R[s,a_{\lambda
}],G_1\circ\beta_{\mu}\in\R[s,b_{\mu}]$,
$G_1\circ\alpha_{\lambda }(0)=0$ and $G_1\circ\beta_{\mu}(0)=1-3b_{\mu}$,
\item [\em (c)\em]
$F_2\circ\alpha_{\lambda }=G_2\circ\alpha_{\lambda
}\in\R[s,a_{\lambda }],F_2\circ\beta_{\mu}=G_2\circ\beta_{\mu}\in\R[s,b_{\mu}]$ and

$F_2\circ\alpha_{\lambda }(0)=G_2\circ\alpha_{\lambda
}(0)=F_2\circ\beta_{\mu}(0)=G_2\circ\beta_{\mu}(0)=0$, 
\end{itemize}
and therefore, the following properties hold:
\begin{itemize}
\item [\em (i) \em] The polynomials $F,G$ are non negative in $\R^2$,
\item [\em (ii) \em] $F^{-1}(0)=F_1^{-1}(0)\cap F_2^{-1}(0)=\{(0,-1)\}$ whose image by $P$
is $\{(0,1)\}$ and 

$G^{-1}(0)=G_1^{-1}(0)\cap G_2^{-1}(0)=\{(-1,0)\}$ whose image by $P$ is $\{(1,0)\}$,
\item [\em (iii) \em]
$P\circ\alpha_{\lambda
}=(F\circ\alpha_{\lambda },G\circ\alpha_{\lambda
})=((1-a_\lambda)^2+\cdots,g_1(a_\lambda)s^2+\cdots)$ and

$P\circ\beta_{\mu}=(F\circ\beta_{\mu},G\circ\beta_{\mu})=(f_1(b_\mu)s^2+\cdots,(1-3b_\mu)^2+\cdots)$ 
\end{itemize}
for certain polynomials $g_1\in\R[a_{\lambda}]$, $f_1\in\R[b_{\mu}]$. The information above
does not prove that the image of $P$ is the open quadrant, but guarantees the necessary
condition ($\ast$).

\begin{sremark}
\em
From \em (i) \em and \em (ii) \em above it follows also that
$P(\R^2)\subset Q\cup\{(1,0),(0,1)\}$ and that the preimage of $\{(1,0),(0,1))\}$ is the
finite set $\{(-1,0),(0,-1)\}$. Our next aim is to prove that the previous inclusion is, in
fact, an equality. Next, if
$\varphi:\R^2\rightarrow\R^2$ is a map with image
$\R^2\setminus\{(-1,0),(0,-1)\}$ (which exists by \ref{fp}) the composition
$\Phi=P\circ\varphi$ gives the desired result.
\em
\end{sremark}

\begin{proofq}
To prove that $P(\R^2)\supset Q$ it is enough to show that for all $v>0$ the image of the
restriction $F:\{G=v\}\rightarrow \R$ contains the open interval $(0,+\infty)$. Let us fix
from now on a positive real number $v$. We proceed in several steps: 

\em Step 1. Parametrization of the curve $\{G-v=0\}$\em. Solving the equation
$G-v=0$, which has degree $2$ with respect to $y$, we obtain the roots
\begin{equation*}
\begin{split}
&y^+(x,v)=\frac{1+x+x^3+x^4+\sqrt{\Delta(x,v)}}{x(x^2+(x^3+1)^2)}\\
&y^-(x,v)=\frac{1+x+x^3+x^4-\sqrt{\Delta(x,v)}}{x(x^2+(x^3+1)^2)}
\end{split}
\end{equation*}
where $\Delta(x,v)=v(x^2+(x^3+1)^2)-x^2(x+1)^2$.

\begin{center}\setlength{\unitlength}{.75mm}
\begin{picture}(70,86)
%\put(-25,-2){\special{illustration:g-v.eps scaled 290}}
\put(-25,-2){\includegraphics[width=9.5cm]{g-v}}
\put(6,60){\tiny$\displaystyle G-0.8=0$}
\put(-18,37.5){\tiny$\displaystyle x$}
\put(40,80){\tiny$\displaystyle y$}
\end{picture}
\end{center}


Let $D_v=\{x\in\R:\ \Delta(x,v)\geq 0, x\neq 0\}$ be its common domain and consider the
functions
$$
\begin{array}{rcclcccrccl}
\gamma_v^+:&D_v&\rightarrow&\R& & & &\gamma_v^-:&D_v&\rightarrow&\R\\
 &x&\mapsto&F(x,y^+(x,v))& & & & &x&\mapsto&F(x,y^-(x,v))
\end{array}
$$

Notice that the image $F(\{G-v=0\})$ is the union $\im\gamma_v^+\cup\im\gamma_v^-$.

\em Step 2. Main properties of the functions $\gamma_v^+,\gamma_v^-$\em. We show that:
\begin{itemize}
\item [$(i)$] $\lim_{x\rightarrow \pm\infty}\gamma_v^+(x)=\lim_{x\rightarrow
\pm\infty}\gamma_v^-(x)=0.$
\item [$(ii)$] $\lim_{x\rightarrow 0}\gamma_v^+(x)=+\infty,\quad \lim_{x\rightarrow
0}\gamma_v^-(x)=
\left\{\begin{array}{ll}  +\infty& \text{ for $v\neq 1$}\\
4 &
\text{for $v=1$}
\end{array} \right.
$ 
\end{itemize}

In fact, an straighforward computation shows that there exist polynomials
$A_1,A_2,B_1,B_2\in\R[x,v]$ and $C(x)=x^2(x^2+(x^3+1)^2)^4$ such that:
\begin{itemize}
\item [\em a) \em] $\gamma_v^+(x)=\dfrac{A_1(x,v)+B_1(x,v)\sqrt{\Delta(x,v)}}{C(x)}\ ;\ \ \
$
$\gamma_v^-(x)=\dfrac{A_2(x,v)+B_2(x,v)\sqrt{\Delta(x,v)}}{C(x)}.$
\item [\em b) \em] $\grad_x(A_1)=\grad_x(A_2)=24\ ;\ \ \ $
$\grad_x(B_1)=\grad_x(B_2)=21.$

Moreover, $\grad_x(\Delta)=6$ and $\grad_x(C)=26.$ 
\end{itemize}

Firstly we analize the behaviour of $\gamma_v^+$ and $\gamma_v^-$ at infinity. Since 
$$
\Delta_v(x)=\Delta(x,v)=v((x^3+1)^2+x^2)-x^2(x+1)^2
$$ 
has even degree and positive leading coefficient as a polynomial in $x$ then it is positive
for
$|x|$ large enough. Thus, from \em a) \em and \em b) \em we conclude \em (i)\em.

Secondly, we study $\gamma_v^+$ and $\gamma_v^-$ at the 
origin. Since $\Delta(0,v)=v>0$ then $0\in\ol{D_v}$. Moreover, from the explicit
computation of $A_i,B_i$, it follows that
\begin{itemize}
\item $A_1(0,v)+B_1(0,v)\sqrt{\Delta(0,v)}=v(1+\sqrt{v})^2>0$,
\item $A_2(0,v)+B_2(0,v)\sqrt{\Delta(0,v)}=v(1-\sqrt{v})^2\geq 0$ and it is $0$ if and only
if $v=1$.
\end{itemize} 

From this we conclude \em (ii)\em. The precise finite value of $\lim_{x\rightarrow
0}\gamma_1^-(x)=4$ is
irrelevant, but to calculate it the explicit formulae of the $A_i$'s, $B_i$'s are needed.

\begin{center}\setlength{\unitlength}{.75mm}
\begin{picture}(145,58)
\put(-20,0){\special{illustration:gamma+.epsf scaled 190}}
\put(75,0){\special{illustration:gamma-.epsf scaled 190}}
\put(4,30){\small $\displaystyle \gamma^+_v$} 
\put(99,30){\small $\displaystyle \gamma^-_v$} 
\end{picture}
\end{center}

To check that $\im\gamma_v^+\cup\im\gamma_v^-\supset (0,+\infty)$ we must study the domain
$D_v$. To that end we determine the union $D=\bigcup_{v>0}D_v$ which is the set
$\{\Delta(x,v)\geq 0, x\neq 0\}$. For that, finding the value of $v$ in
the equation $\Delta(x,v)=0$ we obtain the univariated function defined over the whole $\R$
$$
v(x)=\frac{x^2(x+1)^2}{x^2+(x^3+1)^2}
$$
whose graph is:

\begin{center}\setlength{\unitlength}{.75mm}
\begin{picture}(145,55)
\put(-20,0){\special{illustration:v.epsf scaled 190}}
\put(75,0){\special{illustration:detallev.epsf scaled 190}}
\put(-10,47){\tiny $v=0.82$}
\put(85,47){\tiny $v=0.28^2$} 
\put(90,-3){\tiny Detail of the graphic in the interval (-4,0)} 
\end{picture}
\end{center}

We claim that $v(x)< 0.28^2$ for $x$ in the interval $(-\infty,0)$. Since $v(x)$ is
continuous, to check this it is enough to show that for $v_0=0.28^2$ the polynomial
$\Delta(x,v_0)$ has no negative root, which is verified using Sturm's algorithm. Furthermore,
in view of the previous graphics this bound seems to be quite sharp. Therefore, we will treat
differently the values $v\geq 0.28^2$ and $0<v<0.28^2$. In the first case we have already
proved that $(-\infty,0)\subset D_v$. Since $\gamma_v^+$ is continuous in this interval and
from the limits computed in \em Step 2 \em we conclude:
$$
\text{If $v\geq 0.28^2$, }\quad \im\gamma_v^+\cup\im\gamma_v^-\supset\im\gamma_v^+\supset
(0,+\infty).
$$

To end up with all reduces to check

\em Step 3. If $0<v<0.28^2$ then $\im\gamma_v^+\cup\im\gamma_v^-\supset\im\gamma_v^-\supset
(0,+\infty)$\em. For that it suffices, using \em Step 2\em, to prove that there exist negative
real numbers
$N_v<\delta_v$ such that
$$
(-\infty,N_v]\cup[\delta_v,+\infty)\subset D_v\qquad \text{and} \qquad \gamma_v^-(N_v)>
\gamma_v^-(\delta_v). \qquad (\ast\ast)
$$

The existence of $N_v,\delta_v$ comes from a detailed analysis of the
set $D_v$. We begin computing the roots of $\Delta_v(x)$ in the field of Puiseux series
$\C(\{v^*\})$: these roots are power series in $\C(\{w\})$ where $w=v^{1/2}$,
and between them we choose
\begin{equation*}
\begin{split}
\eta_v=&-\frac{1}{w}+1+w+w^2+\frac{5}{2}w^3+\cdots\\
\xi_v=&-w-w^2-\frac{5}{2}w^3-6w^4+\cdots
\end{split}
\end{equation*}
which are the most and the less negative roots of $\Delta_v$ in $\R(\{v^*\})$ with respect
to the unique ordering of $\R(\{v^*\})$ that makes $v>0$. In view of this we take
\begin{equation*}
\begin{split}
N_v=&-\frac{1}{w}+1+w+w^2=\eta_v-(\frac{5}{2}w^3+\cdots)<\eta_v\\
\delta_v=&-w-w^2-\frac{5}{2}w^3=\xi_v-(-6w^4+\cdots)>\xi_v.
\end{split}
\end{equation*}
It is not difficult to show that $-\infty<N_v<\delta_v<0$ for $0<v<0.28^2$. To prove
($\ast\ast$) we will proceed as follows. First, we verify that $N_v,\delta_v\in
D_v$; for that, we consider the polynomials $\Delta(N_{w^2},w^2), \Delta(\delta_{w^2},w^2)$
in the variable $w$ and check that they are positive in $(0,0.28)$ using the Sturm algorithm.

\begin{center}\setlength{\unitlength}{.75mm}
\begin{picture}(145,55)
\put(-20,0){\special{illustration:q1.epsf scaled 190}}
\put(65,-1){\tiny$\displaystyle w$}
\put(75,0){\special{illustration:q2.epsf scaled 190}}
\put(161.5,-1){\tiny$\displaystyle w$}
\put(0,30){\tiny$\displaystyle \Delta(N_{w^2},w^2)$}
\put(110,48){\tiny$\displaystyle \Delta(\delta_{w^2},w^2)/w^5$}
\end{picture}
\end{center}

Next, we prove that $(-\infty,N_v]\,\cup\,[\delta_v,+\infty)\subset D_v$. To that end, we
consider  the semialgebraic set $D=\bigcup_{v>0} D_v=\{\Delta(x,v)\geq 0,x\neq 0\}$ whose
boundary is the union of the axis $x=0$ and the curve given by the equation
$$
v=\frac{x^2(x+1)^2}{x^2+(x^3+1)^2},
$$
which is a graph over the axis $v=0$. Then, since the curves
$\{(\delta_v,v):0<v<0.28^2\}\subset D$ and $\{(N_v,v):0<v<0.28^2\}\subset D$ are graphs
over the vertical axis $x=0$, and for $v$ small enough $\delta_v>\xi_v$, $N_v<\eta_v$, we
conclude that the interior of ${D_v}$ contains the intervals $[\delta_v,0)$ and
$(-\infty,N_v]$ for
$0<v<0.28^2$.

\begin{center}\setlength{\unitlength}{.75mm}
\begin{picture}(70,59)
\put(-25,0){\special{illustration:graphD.epsf scaled 215}}
\put(47,60){\tiny$\displaystyle N_v$}
\put(-20,-2){\tiny$\displaystyle x$}
\put(78,62){\tiny$\displaystyle v$}
\put(67,60){\tiny$\displaystyle \delta_v$}
\put(52,30){\tiny$\displaystyle \Delta=0$}
\put(0,40){\tiny$\displaystyle D=\{\Delta\geq 0,x\neq 0\}$}
\end{picture}
\end{center}

Finally, we must only check that $\gamma_v^-(N_v)>\gamma_v^-(\delta_v)$. We recall that
$\gamma_v^-=\frac{A_2+B_2\sqrt{\Delta}}{C}$ where $A_2,B_2,\Delta\in\R[x,v]$ and
$C\in\R[x]$. Consider the polynomials
$$
\begin{array}{rclccrcl}
f_1(w)&=&A_2(N_{w^2},w^2)w^{24}& & &f_2(w)&=&A_2(\delta_{w^2},w^2)\\
g_1(w)&=&B_2(N_{w^2},w^2)w^{21}& & &g_2(w)&=&B_2(\delta_{w^2},w^2)\\
q_1(w)&=&\Delta(N_{w^2},w^2)& & &q_2(w)&=&\Delta(\delta_{w^2},w^2)\\
h_1(w)&=&C(N_{w^2})w^{26}& & &h_2(w)&=&C(\delta_{w^2}).
\end{array}
$$

Then, we have to verify that for $w$ in the interval (0,\,0.28) the function
$$
\frac{\dfrac{f_1}{w^{24}}+\dfrac{g_1}{w^{21}}\sqrt{q_1}}{\dfrac{h_1}{w^{26}}}-\frac{f_2+g_2\sqrt{q_2}}{h_2}>0,
$$
or equivalently, that
$$
\frac{w^2h_2f_1-f_2h_1}{h_1h_2}+\frac{w^5g_1\sqrt{q_1}}{h_1}-\frac{g_2\sqrt{q_2}}{h_2}>0.
$$

It is enough to check that the functions
$$
\frac{w^2h_2f_1-f_2h_1}{h_1h_2},\frac{w^5g_1\sqrt{q_1}}{h_1},-\frac{g_2\sqrt{q_2}}{h_2}
$$
are positive in the interval $(0,0.28)$, and so it suffices to verify that the
polynomials 
$$
L=\frac{w^2h_2f_1-f_2h_1}{w^4},\quad g_1,\quad K=\frac{-g_2}{w^3}
$$ 
are positive in $(0,0.28)$. 

\begin{center}\setlength{\unitlength}{.75mm}
\begin{picture}(140,40)
\put(-30,0){\special{illustration:L.epsf scaled 133}}
\put(38,0){\special{illustration:g1.epsf scaled 133}}
\put(107,0){\special{illustration:K.epsf scaled 133}}
\put(-10,30){\tiny$\displaystyle L$}
\put(50,30){\tiny$\displaystyle g_1$}
\put(130,30){\tiny$\displaystyle K$}
\end{picture}
\end{center}

To check this we use again Sturm's algorithm. Just the proof of the positiveness of $L$ in
$(0,0.28)$ requires some care. To simplify it we write $L$ as $L=L_1+L_2w^{55}+L_3w^{101}$
where $L_1,L_2,L_3\in\R[w]$ are polynomials of respective degrees $54,45,49$; now, applying
Sturm's algorithm to $L_1,L_2,L_3$ we observe that these three polynomials are positive in
(0,\,0.28), which concludes the proof.
\end{proofq}

\section{Some consequences and open problems} 

We begin this section with some consequences of Theorem \ref{q}:
\begin{cor}
Let $l_1,l_2$ be independent linear forms of $R^2$. Then the complementary set of the
closed semialgebraic set $\{l_1\geq 0,l_2\geq 0\}$ is a polynomial image of $R^2$.
\end{cor}
\begin{proof}
It is enough to consider the case $l_1=x,l_2=-y$. Let $G_1,G_2:R^2\rightarrow R^2$ be
polynomial maps such that $G_1(R^2)$ is the open quadrant $Q$ and, with \em complex \em
notation, $G_2(z)=z^3$ where $z=x+iy$. Then the composition $G=G_2\circ G_1$ has the desired
image.
\end{proof}

We can also produce examples of open polynomial images of $R^2$ whose exterior boundary is
not piecewise linear.

\example
Let $f(x,y)=x^2-y^2+x^3$. The semialgebraic set $S=\{f(x,y)>0,x>0\}$ is a polynomial
image of $R^2$. Consider first the parametrization $\alpha(t)=(t^2-1,t(t^2-1))$ of
$\{f=0\}$. Then, $S$ is the image of the quadrant $Q'=\{u>1,v<-1\}$ under the polynomial map
$$
\begin{array}{rccl}
\psi:&R^2&\rightarrow &R^2 \\
 &(u,v)&\mapsto&\alpha(u)+\alpha(v).
\end{array}
$$

\begin{center}\setlength{\unitlength}{.75mm}
\begin{picture}(70,55)
\put(-10,0){\special{illustration:alpha.epsf scaled 190}} 
\end{picture}
\end{center}

As we pointed out in the Introduction the problem discussed here can be formulated in
several contexts. In particular, we recall that a function $f:R^m\rightarrow R$ is \em
regular \em if there exist two polynomials $p,q\in R[x_1,\ldots,x_m]$ such that $q$ has no
real zeros and $f=p/q$. A map $R^m\rightarrow R^n$ is \em regular \em if all of its
components are regular functions.

It is easy to produce examples of semialgebraic subsets of $R^n$, which are regular images
of $R^n$ and not polynomial images of $R^n$.

\examples 
\em i) \em The images of regular functions $R\rightarrow R$ are all the non open intervals.

\em ii) \em The open disc $\D=\{u^2+v^2<1\}$ is a regular image of $R^2$. Indeed, let
$P:R^2\rightarrow R^2$ be a polynomial map whose image is the upper half-plane
$\HH=\{v>0\}$. With \em complex \em notation, the \em M\"obius transform \em
$$
\begin{array}{rccl}
\phi:&\HH&\rightarrow &R^2\\
 & z=u+iv&\mapsto& \dfrac{z-i}{z+i}
\end{array}
$$
maps $\HH$ onto $\D$. Thus $\phi\circ P$ is a regular map whose image is $\D$.

\em iii) \em In contrast with the polynomial case, the exterior $S$ of the closed unit disc
of $R^2$ is a regular image of $R^2$.  For, let
$G_1:R^2\rightarrow R^2$ be a polynomial map whose image is the upper half-plane
$\HH=\{v>0\}$ and such that the fiber $F=G_1^{-1}(0,1)$ is a finite set. By \ref{fp} there
exists a polynomial map $G_2:R^2\rightarrow R^2$ whose image is $R^2\setminus F$. The
image of $\phi\circ G_1\circ G_2$ (where $\phi$ is the one of the previous example) is the
punctured disc $\D\setminus\{(0,0)\}$. Finally, the inversion
$$
\begin{array}{rccl}
\rho:&\D\setminus\{(0,0)\}&\rightarrow &R^2\\
 & z=u+iv&\mapsto& \dfrac{z}{\|z\|^2}
\end{array}
$$
is regular and has $S$ as image.

\em iv) \em The open band $\BB=\{u>0,-1<v<1\}$ is not a polynomial image of $R^2$ by
\ref{proj} (3). However, it is the image of the quadrant $Q''=\{x-y>0,x+y>0\}$  under the
regular map
$$
\begin{array}{rccl}
\sigma:&Q''&\rightarrow &R^2\\
 & (u,v)&\mapsto& (u,\dfrac{v}{u}).
\end{array}
$$

\add\noindent{\bf(\thethm) \quad Some open questions.}

\em {\bf 1.} \em We have already seen that an open polynomial image of $R^2$ in $R^2$ is a
pure dimensional, semialgebraically connected and semialgebraic set $S$ such that $p(S)$ is
unbounded for each non constant polynomial function $p$ on $S$ and whose $\ol{\delta
S}^{\Zar}$ is a finite union of Zariski closures of parametric semilines. Is the converse
true? In particular, is the set $S=\{x>0,y>0,x-y+4>0\}$ a polynomial image of $R^2$?

\em {\bf 2.} \em Analogously, it is not difficult to check that an open regular image of
$R^2$ in $R^2$ is a pure dimensional, semialgebraically connected and semialgebraic set $S$
such that its $\ol{\delta S}^{\Zar}$ is a finite union of real algebraic curves of genus
zero. Is the converse true?

Notice that in this case the set $S$ above is the image of the band $\BB$ under the map
$$
\begin{array}{rccl}
\eta:&\BB&\rightarrow &R^2\\
 & (u,v)&\mapsto& (2x,(x+y+1)(y+1)).
\end{array}
$$

Moreover, using this set $S$ it is not difficult to verify that every euclidean polygon of
3, 4 or 5 vertices is a regular image of $R^2$. Is this true for polygons with more
vertices?

\em {\bf 3.} \em Related with the previous questions it seems interesting to characterize
those regular images of $R^2$ which are not polynomial images of $R^2$ (like the exterior
of the closed unit disc or the open band).

\begin{thebibliography}{9999}

\bibitem[AnBrRz]{abr} C. Andradas, L. Br\"ocker, J.M. Ruiz: Constructible 
sets in real geometry.  \em Ergeb.  Math.  \em {\bf 33}.  Berlin Heidelberg 
New York: Springer Verlag, 1996.

\bibitem[BCR]{bcr} J. Bochnak, M. Coste, M.-F. Roy: G\'eom\'etrie
alg\'ebrique r\'eelle. {\em Ergeb. Math. 12}, Springer-Verlag,
Berlin Heidelberg New York (1987).

\bibitem[DK]{dk} H. Delfs, M. Knebusch: Semialgebraic topology over a real closed field II. Basic
theory of semialgebraic spaces, \em Math. Z. \em {\bf 178}, no. 2, 175-213 (1981). 

\bibitem[G]{g} J.M. Gamboa: Reelle algebraische Geometrie, June,
$10^{\text{th}}-16^{\text{th}}$ (1990), Oberwolfach.

\bibitem[GU]{gu} J.M. Gamboa, C. Ueno: Proper polynomial maps: the real case, \em Lecture Notes in Math. \em
1524, 240-256, Berlin: Springer, 1992. \em Real algebraic geometry (Rennes, 1991)\em.

\bibitem[J]{j} Z. Jelonek: A geometry of polynomial transformations of the real plane, \em 
Bull. Polish Acad. Sci. Math \em {\bf 48}, no. 1, 57-62 (2000).

\bibitem[P]{p} S. Pinchuk: A counterexample to the real Jacobian Conjecture, \em Math. Z.
\em {\bf 217}, 1-4 (1994).

\bibitem[Rz]{r} J.M. Ruiz: Semialgebraic and semianalytic sets, \em Cahiers d'Histoire des 
Math\'e\-ma\-ti\-ques\em, {\bf s\'er. 2}, no. 1, 59-70 (1991), Institut Henri Poincar\'e.

%\bibitem[Sh]{sh}

 

\end{thebibliography}

\makeatletter
 
\noindent Depto: Algebra\\ 
F. Ciencias Matem\'aticas\\
Universidad Complutense de Madrid\\
28040 Madrid, Spain\\
e-mail: josefer@mat.ucm.es\\
e-mail: jmgamboa@mat.ucm.es
\makeatother
\end{document}