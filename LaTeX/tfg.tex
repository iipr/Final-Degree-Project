 \documentclass[11pt, a4paper, english, twoside, notitlepage, openright]{report}

\usepackage[a4paper, total={15cm, 22cm}]{geometry}
\usepackage{iipr}
\fancyhead[RO, LE]{ }
\fancyhead[LO]{\nouppercase \leftmark}	% Heading on odd pages: Chapter name on the left
\fancyhead[RE]{\nouppercase \rightmark} % Heading on even pages: Section on the right
\fancyfoot[LE,RO]{\thepage} % Roman numbering, foot left on even, foot right on odd pages
\fancyfoot[CE]{Double Degree in Mathematics and Computer Science} %Foot: Center, even pages
\fancyfoot[CO]{Complutense University of Madrid (UCM)} %Foot: Center, odd pages
\renewcommand{\footrulewidth}{0.4pt} % Rule on top of foot
\renewcommand{\headrulewidth}{0.4pt} % Rule below headings
\pagestyle{fancy}


\begin{document}

\pagenumbering{roman}
\begin{titlepage}

\title{\Huge{\textsc{Complexity Analysis of\\
Polynomial Algorithms}} \\
\vspace{0.5cm}
\Large{\textsc{Final Degree Project}}\\
\vspace{1.5cm}
\protect\includegraphics[scale=0.9]{escudo_ucm.pdf}
\vspace{1.5cm}}
\author{\textbf{Ignacio Iker Prado Rujas} \\
Complutense University of Madrid (UCM) \\
Double Degree in Mathematics and Computer Science}
\date{\today}
\maketitle
\thispagestyle{empty}

\begin{center}
\textbf{Tutors:} \\
\textbf{Juan R. Delgado, Jos\'e F. Fernando \textit{\&} Jos\'e M. Gamboa} \\
\vspace{0.1cm}
Algebra Department, Mathematics Faculty
\end{center}

\end{titlepage}

\mbox{}
\thispagestyle{empty}
\newpage	
\thispagestyle{empty}
\begin{abstract} This work is about different proofs of the same fact and a computational comparison between them, looking for the most efficient one.

Let $R$ be a real closed field and $n\geq 2$. Then: 
	
(1) For every finite subset $F$ of $R^n$, the semialgebraic set $R^n\setminus F$ is a polynomial image of $R^n$. 
	
(2) Given linearly independent linear forms $h_1,\dots,h_r$ of $R^n$, the semialgebraic set $\{h_1>0,\dots,h_r>0\}\subset R^n$ is a polynomial image of $R^n$.
	
The key result here is that $\Qu:=\{x>0,y>0\}\subset R^2$ is a polynomial image of $R^2$. This assert is proved in three different ways: a first approach using some basic results in real algebraic geometry (such as Sturm's theorem and the Curve Selection Lemma) and the aid of a computer; a second and shorter one, using the composition of three rather simple polynomial maps; and a third one that applies arguments of algebraic topology, without the aid of computer computations.

(...)

\vspace{0.2cm}
\textit{Keywords.} Polynomial map, polynomial image, semialgebraic set, open quadrant, complexity.


\vspace{0.3cm}
\begin{center}
\textbf{Resumen}
\end{center}

Este trabajo contiene distintas pruebas del mismo hecho y pretende hacer una comparaci\'on computacional entre ellas, tratando de encontrar la m\'as eficiente.

Sean $R$ un cuerpo real cerrado y $n\geq 2$. Entonces: 
	
(1) Para cada subconjunto finito $F$ de $R^n$, el conjunto semialgebraico $R^n\setminus F$ es imagen polin\'omica de $R^n$. 
	
(2) Dadas formas linealmente independientes $h_1,\dots,h_r$ de $R^n$, el conjunto semialgebraico $\{h_1>0,\dots,h_r>0\}\subset R^n$ es imagen polin\'omica de $R^n$.
	
El resultado clave aqu\'i es que $\Qu:=\{x>0,y>0\}\subset R^2$ es imagen polin\'omica de $R^2$. Esta afirmaci\'on es probada de tres maneras diferentes: una primera usando algunos resultados b\'asicos de geometr\'ia algebraica real (como son el teorema de Sturm y el Lema de Selecci\'on de Curvas) y la ayuda de un ordenador; una segunda forma m\'as breve, empleando la composici\'on de tres aplicaciones polinomiales bastante sencillas; y una tercera y \'ultima en la que se utilizan  argumentos de topolog\'ia algebraica, que evitan efectuar c\'alculos en un ordenador. 

(...)

\vspace{0.2cm}
\textit{Palabras clave.} Aplicaci\'on polinomial, imagen polinomial, conjunto semialgebraico, quadrante abierto, complejidad.


\end{abstract}

\tableofcontents
\thispagestyle{empty}

\begin{chapter}{Introduction to polynomial images of $R^n$}
\pagenumbering{arabic}    % Numbering from 1

\begin{section}{Statement of the problem and main results}
\begin{definition}\label{polyMap} Given a \hyperref[realCField]{real closed field} $R$ and positive integers $m,n$ it is said that $f:=(f_1,\dots,f_n):R^m\to R^n$ is a \em polynomial map \em if $f_i\in R[{\tt x}_1,\dots,{\tt x}_m]$ for $i=1,\dots,n$. 
\end{definition}

An important example of real closed field (and the only one with the Archimedean property) if the field $\R$ of real numbers. There are several concepts, like the one of real closed field, that appear in the Introduction but that we do not recall until Appendix \ref{AA} in order to lighten the presentation and soften the reading.
	
A very famous theorem by Tarski and Seidenberg states the following:
\begin{theorem}[\em Tarski-Seidenberg\em]\label{tarskiSeidenberg} \em The image of every polynomial map $f: R^m \longrightarrow R^n$ is a \hyperref[semialgSet]{semialgebraic subset} of $R^n$. \em
\end{theorem}

In this work we study a sort of converse of this statement. In the 1990 \emph{Oberwolfach Reelle algebraische Geometrie} week, J.M. Gamboa \cite{g} proposed the following
\begin{problem}
Characterize the semialgebraic subsets of $R^n$ that are polynomial images of some $R^m$.
\end{problem}
Particularly interesting seems to be the study of those open semialgebraic subsets of $R^n$ that are polynomial images of $R^n$, because this is related with the real jacobian conjecture.
	
\begin{notation} We need to mention to which topology we refer to when we talk about closures, boundaries, etc. More specifically, the \em exterior boundary \em of a subset $S\subset R^n$ is $\delta S:=\overline{S}\setminus S$, with $\overline{S}$ being the \em closure \em of $S$ in the usual topology of $R^n$. In addition we will denote by $\overline{S}^{\text{zar}}$ the closure of $S$ with respect to the \hyperref[zariski]{Zariski topology} of $R^n$. We will say that a semialgebraic subset $A\subset R^n$ is \em Zariski-irreducible \em if its Zariski closure $\overline{A}^{\text{zar}}$ is an irreducible algebraic set.
\end{notation}
	
\begin{subsection}{Necessary conditions and examples} To begin working on this idea, we provide some necessary conditions for a set $S\subset R^n$ to be a polynomial image of $R^m$. 
	
If $m=n=1$, that is, for a polynomial function $f:R\to R$, its image $f(R)$ is either a \em singleton, \em that is, a set with a unique point if the function $f$ is constant, or an unbounded closed interval. For example if $f({\tt x})={\tt x}^2$ we have $f(R)=[0,+\infty)$, and $f(R)=R$ if $f$ is a polynomial of odd degree.
	
In the general case, by \hyperref[tarskiSeidenberg]{Tarski-Seidenberg}, $S$ must be a semialgebraic set and, as $R^n$ is semialgebraically connected, $S$ is semialgebraically connected too. In addition, by the identity principle for polynomials, $S$ is Zariski-irreducible and \hyperref[pureDim]{pure dimensional}.
	
	% Añadir el teorema de Shiota y la definición de Nash map? NO
	
But to be a polynomial image of some $R^m$ is a restrictive condition, and there are more constrains than those quoted above. 
	
\begin{definition} A polynomial map $f:R^m\to R^n$ is said to be \em semialgebraically proper at a point $p\in R^n$ \em if there exists an open neighbourhood $K$ of $p$ such that the restriction $f|_{f^{-1}(K)}:f^{-1}(K)\to K$ is a \hyperref[properMap]{semialgebraically proper map}.
\end{definition}
	
\begin{definition} A \em parametric semiline \em of $R^n$ is the image of $R$ under a non-constant polynomial map $R\to R^n$.
\end{definition}
	
It is clear that every parametric semiline is semialgebraically closed, since every polynomial map from $R$ to $R^n$ is semialgebraically proper. Let $\S_f$ denote the set of points $p\in R^n$ at which $f$ is \textbf{not} semialgebraically proper.
	
\begin{theorem}[\em Jelonek\em]\label{jelonek}\em Let $f:R^2\to R^2$ be a \hyperref[dominant]{dominant} polynomial map. Then $\S_f$ is a finite union of parametric semilines.\em
\end{theorem}
	
With these ideas in mind, we present in the following proposition some obstructions for a semialgebraic set to be a polynomial image of $R^n$. 
\begin{proposition}\label{propIntro} Let $f: R^m\to R^n$ be a polynomial map and $S:=f(R^m)$.
\begin{enumerate}[\em(1)\em]
\item $\delta S \subset\S_f$.
\begin{Proof} Suppose $p\in\delta S\setminus \S_f$. Since $p\notin\S_f$, there exists an open neighbourhood $K$ of $p$ such that the restriction $f|_{f^{-1}(K)}:f^{-1}(K)\to K$ of $f$ is proper. Thus its image $K\cap S$ is a closed subset of $K$. Hence, $p\in K\cap\overline{S}=K\cap(\overline{K\cap S})=K\cap S$, which yields in a contradiction.
\end{Proof}
\item Let $m=n=2$ and $\Gamma$ be a $1$-dimensional irreducible component of $\overline{\delta S}^{\text{zar}}$. Then $\Gamma$ is the Zariski closure of a parametric semiline of $R^2$.
\begin{Proof} As $f$ is a dominant map, $\S_f$ is, by Theorem \ref{jelonek}, a finite union of parametric semilines, say $M_1,\dots, M_s$ in $R^2$. Using (1) we get: $\Gamma\subset\overline{\delta S}^{\text{zar}}\subset \overline{\S_f}^{\text{zar}}=\bigcup_{i=1}^s\overline{M_i}^{\text{zar}}$. Lastly, using that both $\Gamma$ and the $\overline{M_i}^{\text{zar}}$'s are irreducible, $\Gamma=\overline{M_i}^{\text{zar}}$ for some index $i=1,\dots,s$.
\end{Proof}
\item Let $p:R^n\to R$ be a polynomial map which is non-constant on $S$. Then $p(S)$ is unbounded.
\begin{Proof} For each $a \in R^m$ let $\varphi_a:R\to R$ defined as $\varphi_a(t):=p(f(ta))$. Then $p(S)$ would contain the image $\varphi_a(R)$ for all $a\in R^m$. Suppose now that $\varphi_a(R)$ is bounded. Then $\varphi_a(R)$ would be a point $r_a$, and given two points $a,b\in R^m$ we would have
$$ 
\varphi_a(1)=p(f(a))=r_a=\varphi_a(0)=\varphi_b(0)=r_b=p(f(b))=\varphi_b(1).
$$ 
Then $p$ would be constant on $S$, which is a contradiction.
\end{Proof}
\end{enumerate}
\end{proposition}	
\begin{corollary} Because of statement \em (3) \em in Proposition \em \ref{propIntro}, \em all linear projections of a polynomial image $S=f(R^m)$ are either a point or unbounded. Thus, $S$ is also unbounded or a point.
\end{corollary}
	
\begin{examples}\label{introExample}
\
\begin{enumerate}[(i)]
\item The exterior of the closed unit disc $S:=\set{u^2+v^2>1}\subset R^2$ \textbf{is not} a polynomial image of $R^2$. This is so because the only irreducible component of $\overline{\delta S}^{\text{zar}}$ is the circle $\set{u^2+v^2=1}\subset R^2$ and this set is not a parametric semiline because it is bounded.
			
\item Let $S_1:=\set{uv<1}\subset R^2$ and $S_2:=\set{uv>1,u>0}\subset R^2$ (see Figure \ref{fig:introExampleii}). They both \textbf{are not} polynomial images of $R^2$ since the Zariski closure of their exterior boundaries $\overline{\delta S_1}^{\text{zar}}=\overline{\delta S_2}^{\text{zar}}$ is the hyperbola $\{uv=1\}\subset R^2$, which is not a parametric semiline.
\begin{figure}[h]\hspace{0.1cm}
\begin{subfigure}{.49\linewidth}\centering
\includegraphics[width=1\textwidth]{plots/ch1_01_S_1.pdf}
\caption{$S_1:=\set{uv<1}$.\label{fig:S_1}}
\end{subfigure}
\begin{subfigure}{.49\linewidth}\centering
\includegraphics[width=1\textwidth]{plots/ch1_02_S_2.pdf}
\caption{$S_2:=\set{uv>1,u>0}$.\label{fig:S_2}}
\end{subfigure}\\[1ex]
\caption{Plots of the regions defined in Example \ref{introExample} (ii).\label{fig:introExampleii}}
\end{figure}
\item Let $S:=R^2\setminus\set{(0,0)}$ be the punctured plane. Then $S$ is the image of the polynomial map $(x,y) \mapsto (xy-1,(xy-1)x^2-y)$.
\item The open upper half-plane $\H:=\set{v>0}\subset R^2$ is the image of the polynomial map 
$$
R^2\to R^2,\, (x,y)\mapsto (y(xy-1),(xy-1)^2+x^2),
$$
This implies that every open half-plane is a polynomial image of $R^2$. This is probably the simplest polynomial map whose image is $\H$.
\end{enumerate}
\end{examples}
\end{subsection}
	
\begin{subsection}{Statement of the main results}
	
The main results of this chapter are generalizations of items (iii) and (iv) from Examples \ref{introExample}.
%\vspace{0.35cm}
\begin{theorem}\label{finSetTh}\em Let $n\ge2$. For every finite set $F\subset R^n$, the semialgebraic set $R^n\setminus F$ is a polynomial image of $R^n$.\em
\end{theorem}
%\vspace{0.35cm}
\begin{theorem}\label{openQuadGen}\em Let $n\ge 2$. Given independent linear forms $h_1,\dots,h_r$ of $R^n$, the open semialgebraic set $\set{h_1>0,\dots,h_r>0}$ is a polynomial image of $R^n$.\em
\end{theorem}
	
Before the paper \cite{fg} was published, the exterior boundary of all open sets that were known to be polynomial images of $R^2$ was Zariski-irreducible, and all of them were deformations of $\H$. J.M. Gamboa outlined the problem of finding if the open quadrant $\Qu:=\set{x>0,y>0}\subset R^2$ is a polynomial image of $R^2$ or not, since its exterior boundary is Zariski-reducible. The solution of this problem is a key particular case of the content of Theorem \ref{openQuadGen}. Before that, the closest known approach to look for a solution of this problem was the transformation
$$
\psi:R^2 \to R^2,\, (x,y)\mapsto(x^4y^2,x^2y^4)
$$	
whose image is $\Qu\cup\set{(0,0)}$. The answer to the first intriguing problem in this field was given in the following theorem:
\begin{theorem}\label{openQuad}\em The first open quadrant $\Qu$ is a polynomial image of $R^2$.\em
\end{theorem}
	
\begin{remark} The first proof of Theorem \ref{openQuad} consists of two parts:
\begin{itemize}
\item Choosing a ``good'' candidate to be a polynomial map whose image is close enough to $\Qu$, and giving the reasons behind this choice (see section \ref{quadReasons}). 
	
\item Checking that the image of the map is $\Qu$ indeed. After some arguments, this can be reduced to prove the non-existence of real roots of certain polynomials in one variable on certain intervals, and to compare some rational functions on those intervals. In order to do this, we use symbolic computations with tools like Sage and Maple. Because of the high degree of the involved polynomials, the actual checking of the non-existence of roots is done with a Maple package that performs \hyperref[sturm]{Sturm algorithm} and a Python programme that implements \hyperref[laguerre]{Laguerre's method}.
\end{itemize}
\end{remark}

Let us see how Theorem \ref{openQuadGen} follows from Theorem \ref{openQuad}.
		
\vspace{1mm}		
		
[Proof of Theorem \ref{openQuadGen}] After a linear change of coordinates we can suppose that $h_1:={\tt x}_1,\dots,h_r:={\tt x}_r$, so we only have to prove that for every pair of positive integers $r\leq n$ the semialgebraic set $\{x_1>0,\dots,x_r>0\}\subset R^n$ is a polynomial image of $R^n$. This is reduced to prove the following two steps:
\begin{itemize}
\item $\H:=\{x_1>0\}\subset R^2$ and $\Qu:=\{x_1>0,\,x_2>0\}\subset R^2$ are polynomial images of $R^2$, which is true, respectively, by Example \ref{introExample} (iv) and Theorem \ref{openQuad}.
\item This implies that $\mathscr{O}:=\{x_1>0,\, x_2>0,\, x_3>0\}\subset R^3$ is a polynomial image of $R^3$. Indeed, let $f,g:R^2 \rightarrow R^2$ be polynomial maps whose respective images are $\H$ and $\Qu$. Let us define:
\begin{align*}
(f,\text{id}_R): R^3=R^2\times R&\longrightarrow R^3= R^2\times R\\
(x_1,x_2,x_3) &\longmapsto (f_1(x_1, x_2),\, f_2(x_1, x_2),\, x_3)\\
(\text{id}_R,g): R^3=R\times R^2&\longrightarrow R^3= R\times R^2\\
(x_1,x_2,x_3) &\longmapsto (x_1,\, g_1(x_2, x_3),\, g_2(x_2, x_3)).
\end{align*}
Then, $\mathscr{O}$ is the image of the polynomial map 
\begin{align*}
H:=(\text{id}_R,g)\circ(f,\text{id}_R):R^3&\longrightarrow R^3\\
(x_1,x_2,x_3) &\longmapsto (f_1(x_1, x_2),\, g_1(f_2(x_1, x_2), x_3),\, g_2(f_2(x_1, x_2), x_3)).
\end{align*}
\end{itemize} 
Once the case $n=3$ is solved the case of arbitrary $n$ follows straightforwardly, by taking $g \times \overset{k}{\cdots} \times g: R^n \longrightarrow R^n$ when $n=2k$ and $H \times g \times \overset{k-1}{\cdots} \times g: R^n \longrightarrow R^n$ when $n=2k-1$. \qed

\vspace{1mm}
		
The original proofs of Theorems \ref{finSetTh} and \ref{openQuad} are written for $R:=\R$. As for both theorems explicit polynomial maps are given, the results can be extended to arbitrary real closed field $R$ by the \hyperref[TP]{Transfer Principle}.
\end{subsection}
\end{section}

\begin{section}{Complementary set of a finite set}
	
We proceed to prove Theorem \ref{finSetTh}:
	
\vspace{1mm}
	
[Proof of Theorem \ref{finSetTh}] Let $F:=\{p_1,\dots,p_k\}$. Let us see that it suffices to prove the result for points of the form $p_j:=(a_j,\vec{0})\in\R\times\R^{n-1}$. After a linear change of coordinates we can assume that the first coordinates of the given points are pairwise distinct. 

In other words, we denote $p_j:=(a_{1j},\dots,a_{nj})$ and we may suppose that $a_{1j}\neq a_{1\ell}$ when $j\neq\ell$. Then, there exists a polynomial $P_1\in\R[{\tt t}]$ such that $P_1(a_{1j})=a_{nj}$, with $j = 1,\dots, n$, and denoting $x':=(x_1,\dots,x_{n-1})$, we  define the polynomial map 
$$
h_1:\R^n\to\R^n,\, (x',x_n)\mapsto (x',x_n+P_1(x_1)).
$$
Indeed $h_1$ is bijective. Note first that every point of $\R^n$ has a preimage in $\R^n$, namely if $x:=(x_1, \dots,x_n)$, then $z:=(x',x_n-P_1(x_1))$ satisfies $h_1(z)=x$ and $h_1$ is onto. As for being injective, let $x,y\in\R^n$ such that 
$$
h_1(x)=(x_1,\dots,x_n+ P_1(x_1))=(y_1,\dots,y_n+ P_1(y_1))=h_1(y).
$$ 
Then $x_i=y_i$ for $i=1,\dots,n-1$. Also $x_n+P_1(x_1)=y_n+P_1(y_1)$ and $P_1(x_1)=P_1(y_1)$ because $x_1= y_1$. Therefore $x_n=y_n$ and $x=y$.
		
Now, for $p_j':=(a_{1j},\dots,a_{(n-1)j},0)$ we have $h_1(p_j')=p_j$. Analogously, there exists $P_2\in\R[{\tt t}]$ such that $P_2(a_{1j}) = a_{(n-1)j}$, and define the polynomial bijection
$$
h_2:\R^n\longrightarrow \R^n,\,(x'',x_{n-1},x_n)\mapsto (x'',x_{n-1}+P_2(x_1),x_n),
$$
where $x'':=(x_1,\dots,x_{n-2})$. Then $h_2(p_j'')=p_j'$ for $p_j''= (a_{1j},\dots,a_{(n-2)j},0,0)$. In this way the polynomial bijection $h_1\circ h_2:\R^n\to\R^n$ satisfies
$$
(h_1\circ h_2)(p_j'')=h_1(h_2(p_j''))=h_1(p_j')=p_j,
$$
and we can inductively construct a polynomial bijection $h:\R^n\rightarrow\R^n$ such that $h(q_j)=p_j$ for $q_j:=(a_{1j},\vec{0})\in\R\times\R^{n-1}$. Now let $G:=\{q_1,\dots,q_k\}$ and suppose that there exists a polynomial map $g:\R^n\rightarrow\R^n$ such that $g(\R^n)=\R^n\setminus G$. Then $(h\circ g)(\R^n) = \R^n \setminus F$, which concludes the first part of the proof. Thus in what follows we suppose that $p_j:=(a_j,\vec{0})$.
		
We claim that the image of the polynomial map $f:=(f_1,\dots,f_n)$ defined as:
$$
f({\tt x}):=\left({\tt x}_1{\tt x}_2-r+a_1,\ {\tt x}_1^{4}\rho({\tt x})+{\tt x}_1^{2}\sigma({\tt x})+{\tt x}_2,\ {\tt x}_3,\dots,\ {\tt x}_n\right)\quad\text{for ${\tt x}:=({\tt x}_1,\ldots,{\tt x}_n)\in\R^n$}
$$
is $\R^n\setminus F$, where $r$ is an integer such that $r\neq a_1-a_j$ for $j=1,\dots,k$,  
$$
\sigma({\tt x}):=\sum_{j=3}^n{\tt x}_j^2 \, \, \text{ and } \, \, \rho({\tt x}):=\prod_{j=1}^k({\tt x}_1{\tt x}_2-r+a_1-a_j).
$$
First, suppose that there exists $b:=(b_{1},\dots,b_{n})\in R^n$ with $f(b)=p_\ell$ for some $\ell=1,\dots,k$. Then $f_1(b)=b_1b_2-r+a_1=a_\ell$. Thus the $\ell^{th}$-factor of the polynomial $\rho$ evaluated at $x:=b$ is
$$
b_1b_2-r+a_1-a_\ell=a_\ell-a_\ell=0,
$$		 
and $\rho(b)=0$. In addition, the equality $f(b)=p_\ell=(a_{_\ell},\vec{0})$ implies that $f_i(b)=0$ for $i=2,\dots,n$. In particular, as $f_i\equiv\text{id}$ for $i=3,\dots,n$ we get $b_i=0$ for $i=3,\dots,n$. Consequently $\sigma(b)=0$. Since $\sigma(b)=\rho(b)=0$ we get $b_2=f_2(b)= 0$, so $b_2=0$ and $a_{\ell}=f_1(b)=a_1-r$, that is, $r=a_1-a_\ell$, which is a contradiction. So $\text{im}(f)\subset \R^n\setminus F$.
Conversely, let $u:=(u_1,\dots,u_n)\in\R^n\setminus F$. We must prove that the system of polynomial equations:
\[ \begin{cases} 
f_1({\tt x})={\tt x}_1{\tt x}_2-r+a_1=u_1 \\
f_2({\tt x})={\tt x}_1^4\rho({\tt x})+{\tt x}_1^2\sigma({\tt x})+{\tt x}_2=u_2 \\
f_j({\tt x})={\tt x}_j=u_j,\quad j\geq 3
\end{cases}  \]
has a solution.
\begin{enumerate}[(i)]
\item If $u_1=a_1-r$ then $f(0,u_2,\dots,u_n)=u$.
\item If $u_1\neq a_1-r$ we use the first equation to substitute 
\end{enumerate}
$$
{\tt x}_2=\frac{u_1-a_1+r}{{\tt x}_1} \quad \text{ and } \quad {\tt x}_j=u_j \quad \text{ for } j\geq 3.
$$ 
Next, we expand $f_2({\tt x})$:
$$
{\tt x}_1^4\rho({\tt x})+x_1^2\sigma({\tt x})-u_2=-{\tt x}_2=-\frac{u_1-a_1+r}{{\tt x}_1},
$$ 
and multiplying by ${\tt x}_1$ we get 
\begin{equation}\label{quintica}
{\tt x}_1^5\rho({\tt x})+{\tt x}_1^3\sigma({\tt x})-u_2{\tt x}_1+(u_1-a_1+r)=0.
\end{equation}
Then, $\rho({\tt x})=\prod_{j=1}^k(u_1-a_j) \text{ and } \sigma({\tt x})=\sigma(u)$. Now it is clear that each solution $x_1$ of equation \eqref{quintica} must be a nonzero root of the polynomial:
$$
Q({\tt t})=\Big(\prod_{j=1}^k(u_1-a_j)\Big){\tt t}^{5}+\sigma(u){\tt t}^{3}-u_2{\tt t}+(r-a_1+u_1),
$$
which has odd degree, and so it has a real root, unless 
$$
\prod_{j=1}^k(u_1-a_j)=\sigma(u)=u_2=0.
$$ 
If this were the case, then $u_1=a_j$ for some $j= 1,\dots,k$ and $u_2=u_3=\cdots=u_k=0$. This is not possible because $u\not\in F$. Thus, $Q({\tt t})$ has a real root, say $b_1$, and in fact $b_1\neq0$ because $Q(0)=r-a_1+u_1\neq 0$.
Finally, 
$$
f\left(b_1,\ \frac{u_1-a_1+r}{b_1},\ u_3,\ \dots,\ u_n\right)=u,
$$
as required.

\qed
\end{section}
\end{chapter}

\begin{chapter}{The open quadrant $\Qu$ problem: First proof}
\begin{section}{How to find a ``potential'' map to solve the problem}\label{quadReasons}
		
It is remarkable that though the open interval $I:=(0,+\infty)$ is the image of $\R^2$ under the polynomial map $h:\R^2\to\R,\, (x,y)\mapsto (xy-1)^2+x^2$, see Figure \ref{fig:h(x,y)}, the interval $I$ is not a polynomial image of $\R$ because polynomial images of the real line are closed subsets of $\R$.
\begin{figure}[h]
\begin{center}
\includegraphics[width=0.8\textwidth]{plots/ch1_03_f(x,y).png}
\caption{$h({\tt x},{\tt y})=({\tt x}{\tt y}-1)^2+{\tt x}^2$.\label{fig:h(x,y)}}
\end{center}
\end{figure}
		
However, although $h(\R^2)=I$, the polynomial $h$ does not help to obtain $\Qu$ at all:
\begin{remark}
There is no polynomial map $f:=(P_1, P_2):\R^2\to\R^2$ satisfying $f(\R^2)=\Qu$ and $P_1({\tt x},{\tt y})=({\tt x}{\tt y}-1)^2+{\tt x}^2$.
\end{remark}
The proof of this remark relies on a suitable use of the Curve Selection Lemma (\cite[VIII.2.6]{abr}) to approach a point $(\lambda^2,0)\in\overline{\Qu}$ with $\lambda>0$, to get a contradiction.
		
On the topic of finding a polynomial map $\Phi:\R^2\to\R^2$ that satisfies $\Phi(\R^2)=\Qu$, ``a major difficulty" is the following:
\begin{center}
\begin{tabular}{rr}
$\qquad \qquad\quad$ \fbox{\textit{The closure of its image must contain the positive half-axes.}} & $\quad \quad$ ($\clubsuit$)
\end{tabular}
\end{center}
\begin{remark} Using Theorem \ref{finSetTh}, we just need to find a polynomial map $$\P=(\F,\G):\R^2\to\R^2$$ such that $\P(\R^2)$ is the disjoint union of $\Qu$ and a set with finite preimage, say $\P(\R^2)=\Qu\ \sqcup F$ with $\P^{-1}(F)$ a finite set. Suppose for a while this is proved. Then, by Theorem \ref{finSetTh}, there exists a polynomial map $\varphi:\R^2\to\R^2$ such that $\varphi(\R^2)=\R^2\setminus\P^{-1}(F)$ and the polynomial map $\Phi:=\P\circ\varphi$ satisfies
$$
\Phi(\R^2)=\P(\varphi(\R^2))=\P(\R^2\setminus\P^{-1}(F))=\P(\R^2)\setminus F=(\Qu\ \sqcup F)\setminus F=\Qu.
$$ 
\end{remark}
We are going to define a map $\P:=(\F,\G)$ that accomplish this task, with the set $F$ being $F:=\set{(-1,0),(0,-1)}$. If we were able to find such map $\P$, then condition ($\clubsuit$) will immediately be satisfied. 
		
Suppose for a while that such a map $\P$ exists. Then, for every $\lambda,\mu\ge 0$ there will exist \hyperref[curveGerms]{Nash half-branch curve germs} $\alpha_{\lambda}(s),\beta_{\mu}(s)$ which cannot be extended to $0$ and such that:
$$
\lim_{s\rightarrow 0} P(\alpha_{\lambda}(s))=(\lambda^2,0)\qquad \text{and} \qquad \lim_{s\rightarrow 0} P(\beta_{\mu}(s))=(0,\mu^2).
$$
We can try parameterizations of the form:
$$
\alpha_{\lambda}(s):=\left(s^{n_{\lambda}},\frac{a_{\lambda 0}+a_{\lambda 1}s+\cdots}{s^{m_{\lambda}}}\right)
\quad \text{ and } \quad
\beta_{\mu}(s):=\left(\frac{b_{\mu 0}+b_{\mu 1}s+\cdots}{s^{\ell_{\mu}}},s^{k_{\mu}}\right).
$$
Then $a_{\lambda 0},b_{\mu 0}$ must be constants (except maybe for finitely many values of $\lambda$ and $\mu$). This leads us to choose curves of the type:
$$
\alpha_{\lambda}(s):=\left(s^{n_{\lambda}},\frac{1+a_{\lambda 1}s+\cdots}{s^{m_{\lambda}}}\right)
\quad \text{ and } \quad
\beta_{\mu}(s):=\left(\frac{1+b_{\mu 1}s+\cdots}{s^{\ell_{\mu}}},s^{k_{\mu}}\right),
$$
and among them we make the simplest choice: 
$$
\alpha_{\lambda}(s):=\left(s,\frac{1+a_{\lambda }s}{s}\right)
\quad \text{ and } \quad
\beta_{\mu}(s):=\left(\frac{1+b_{\mu }s}{s},s^{3}\right).
$$
The following pair of polynomials:
\begin{equation*}
\boxed{
\begin{aligned}
\F({\tt x},{\tt y})&:=(1-{\tt x}^3{\tt y}+{\tt y}-{\tt x}{\tt y}^2)^2+({\tt x}^2{\tt y})^2&=&\ \F_1^2+\F_2^2 \\
\G({\tt x},{\tt y})&:=(1-{\tt x}{\tt y}+{\tt x}-{\tt x}^4{\tt y})^2+({\tt x}^2{\tt y})^2&=&\ \G_1^2+\G_2^2\\
\end{aligned}
}
\end{equation*}
enjoy a nice behavior along these curves, as figure \ref{fig:plotFG} show.
\begin{figure}[h]\hspace{-0.15cm}
\begin{subfigure}{.49\linewidth}\centering
\includegraphics[width=1\textwidth]{plots/ch1_04_F.png}
\caption{$\F({\tt x},{\tt y}):=(1-{\tt x}^3{\tt y}+{\tt y}-{\tt x}{\tt y}^2)^2+({\tt x}^2{\tt y})^2$.\label{fig:F}}
\end{subfigure}
\begin{subfigure}{.50\linewidth}\centering
\includegraphics[width=1\textwidth]{plots/ch1_05_G.png}
\caption{$\G({\tt x},{\tt y})=(1-{\tt x}{\tt y}+{\tt x}-{\tt x}^4{\tt y})^2+({\tt x}^2{\tt y})^2$.\label{fig:G}}
\end{subfigure}\\[1ex]
\caption{Plots of the polynomials $\F,\G:\R^2\longrightarrow\R$.\label{fig:plotFG}}
\end{figure}
Next, notice that
\begin{enumerate}[(a)]
\item $\cdot$ $\F_1\circ\alpha_\lambda=1-a_{\lambda}-a_{\lambda}^{2} s-s^{2}-a_{\lambda} s^{3}\in\R[s,a_{\lambda}]$,
$\qquad\qquad\qquad \,\, \, \,   \F_1\circ\alpha_{\lambda }(0)=1-a_{\lambda. }$ \newline
$\cdot$ $\F_1\circ\beta_{\mu}=-3\,b_{\mu}s-3 \,b_{\mu}^{2} s^{2}-{\left(b_{\mu}^{3}-1\right)}s^{3}-s^{5}-b_{\mu}s^{6}\in\R[s,b_{\mu}]$,
$\, \F_1\circ\beta_{\mu}(0)=0$.
				
\item $\cdot$ $ \G_1\circ\alpha_{\lambda } = {\left(1-a_{\lambda} \right)}s-s^{3}-a_{\lambda} s^{4} \in\R[s,a_{\lambda}]$,
$\qquad\qquad\qquad\qquad\, \, \, \, \,\G_1\circ\alpha_{\lambda }(0)=0$.

$\cdot$ $\G_1\circ\beta_{\mu}=1-3\, b_{\mu}-6\,b_{\mu}^{2}s-{\left(4\,b_{\mu}^{3}+1\right)}s^{2}-{\left(b_{\mu}^{4}+ b_{\mu}\right)}s^{3}\in\R[s,b_{\mu}], \, \, \G_1\circ\beta_{\mu}(0)=1-3b_{\mu}$.
		
\item $\cdot$ $\F_2\circ\alpha_{\lambda }= s+a_{\lambda} s^{2} = \G_2\circ\alpha_{\lambda}\in\R[s,a_{\lambda }]$.
			
$\cdot$ $\F_2\circ\beta_{\mu}= s+2 \, b_{\mu} s^{2}+b_{\mu}^{2} s^{3} = \G_2\circ\beta_{\mu}\in\R[s,b_{\mu}]$.
				
$\cdot$ $\F_2\circ\alpha_{\lambda }(0)=\G_2\circ\alpha_{\lambda}(0)=\F_2\circ\beta_{\mu}(0)=\G_2\circ\beta_{\mu}(0)=0$.
\end{enumerate}
All of these map compositions were computed by Sage. Thus, we get the following properties:
		
\begin{enumerate}[(i)]
		
\item The polynomials $\F,\G$ are non-negative in $\R^2$.
		
\item $\cdot$ $\F^{-1}(0)=\F_1^{-1}(0)\cap \F_2^{-1}(0)=\{(0,-1)\}\xmapsto{\ \P\ }\set{(0,1)}$.
			
$\cdot$ $\G^{-1}(0)=\G_1^{-1}(0)\cap \G_2^{-1}(0)\ =\, \{(-1,0)\} \xmapsto{\ \P\ } \set{(1,0)}$.
		
\item $\cdot$ $\P\circ\alpha_{\lambda}=(\F\circ\alpha_{\lambda },\G\circ\alpha_{\lambda})=$
			
$\arraycolsep=2pt\def\arraystretch{1.2}
\begin{array}{l}
\left(\right.a_{\lambda}^{2}-2 \,a_{\lambda}+1+2 \,{(a_{\lambda}^{3}-a_{\lambda}^{2})}s+{(a_{\lambda}^{4}+2 \, a_{\lambda}-1)} s^{2}+ \,a_{\lambda}^{2} s^{3}+\\
\quad {(2\, a_{\lambda}^{3}+a_{\lambda}^{2}+1)}s^{4}+2 \,a_{\lambda} s^{5}+a_{\lambda}^{2} s^{6},\\		
\ {(a_{\lambda}^{2}-2 \ a_{\lambda}+2)} s^{2}+2 \, a_{\lambda} s^{3}+{(a_{\lambda}^{2}+2 \,a_{\lambda}-2)}s^{4}+\\
\quad \,2 \,{(a_{\lambda}^{2}-a_{\lambda})}s^{5}+s^{6}+2\,a_{\lambda} s^{7}+a_{\lambda}^{2}s^{8}\left.\right).
\end{array}
$
				
$\cdot$ $\P\circ\beta_{\mu}=(\F\circ\beta_{\mu},\G\circ\beta_{\mu})=
$
				
				$\arraycolsep=2pt\def\arraystretch{1.2}
\begin{array}{l}
\left(\right.{(9 \,b_{\mu}^{2}+1)}s^{2}+2 \,{(9 \,b_{\mu}^{3}+2\,b_{\mu})}s^{3}+3\,{(5\,b_{\mu}^{4}+2\,b_{\mu}^{2}-2\,b_{\mu})}s^{4}+\\
\quad 2\,{(3 \,b_{\mu}^{5}+2\,b_{\mu}^{3}-3\,b_{\mu}^{2})}s^{5}+{(b_{\mu}^{6}+b_{\mu}^{4}-2\,b_{\mu}^{3}+6\,b_{\mu}+1)} s^{6}+\\
\quad 12\,b_{\mu}^{2} s^{7}+2\,{(4\,b_{\mu}^{3}-1)}s^{8}+2\,{(b_{\mu}^{4}-b_{\mu})}s^{9}+s^{10}+2\,b_{\mu}s^{11}+b_{\mu}^{2} s^{12},\\
					\ 9 \, b_{\mu}^{2}-6 \, b_{\mu}+1+12 \, {(3 \, b_{\mu}^{3} - b_{\mu}^{2})} s+{(60\, b_{\mu}^{4} - 8 \, b_{\mu}^{3}+6 \, b_{\mu}-1)}s^{2} + \\
					\quad 2 \, {(27\,b_{\mu}^{5}-b_{\mu}^{4}+9\,b_{\mu}^{2}+b_{\mu})}s^{3}+{(28\,b_{\mu}^{6}+20\,b_{\mu}^{3}+6\,b_{\mu}^{2}+1)} s^{4}+\\
					\quad2\,{(4\,b_{\mu}^{7}+5\,b_{\mu}^{4}+2\,b_{\mu}^{3}+b_{\mu})}s^{5}+{(b_{\mu}^{8}+2\,b_{\mu}^{5}+ b_{\mu}^{4} +b_{\mu}^{2})} s^{6}\left.\right).
					\end{array}
$
\end{enumerate}
The polynomials $\F\circ\alpha_{\lambda },\ \G\circ\alpha_{\lambda}\in\R[s,a_{\lambda}]$ and $\F\circ\beta_{\mu},\ \G\circ\beta_{\mu}\in\R[s,b_{\mu}]$ were computed with Sage. As we anticipated before, by condition (ii) the set $F=\set{(-1, 0),(0,-1)}$.
\end{section}
\begin{section}{The first proof for the open quadrant problem} [Proof of Theorem \ref{openQuad}] We are going to prove that $\Qu\subset\P(\R^2)$. To do this it is enough to fix $v>0$ and to see that the image under $\F$ of the curve $\{\G=v\}$ contains the open half-line $(0,+\infty)$.
\begin{center}
\fbox{\textbf{Step 1}} \emph{Parametrization of the curve $\{\G-v=0\}$.}
\end{center}\label{step1}

We start by solving the equation $\G-v=0$, that is, 
$$
(1-{\tt x}{\tt y}+{\tt x}-{\tt x}^4{\tt y})^2+({\tt x}^2{\tt y})^2-v=0
$$ 
As it has degree $2$ with respect to $y$, we can compute its roots $y^+({\tt x},v)$ and $y^-({\tt x},v)$ given by:
\begin{equation*}
\begin{aligned}
y^+({\tt x},v)&:=\frac{1+{\tt x}+{\tt x}^3+{\tt x}^4+\sqrt{\Delta({\tt x},v)}}{{\tt x}({\tt x}^2+({\tt x}^3+1)^2)}\\
y^-({\tt x},v)&:=\frac{1+{\tt x}+{\tt x}^3+{\tt x}^4-\sqrt{\Delta({\tt x},v)}}{{\tt x}({\tt x}^2+({\tt x}^3+1)^2)}\\
\end{aligned}
\end{equation*}
where $\Delta({\tt x},v)=\Delta_v({\tt x}):=v({\tt x}^2+({\tt x}^3+1)^2)-{\tt x}^2({\tt x}+1)^2,\ \text{deg}_{\tt x}(\Delta)=6$. We can see on figure \ref{fig:plotYs_1} how $y^+$ and $y^-$ look like for instance for $v:=0.8$. As we can see on figure \ref{fig:plotYs_2}, for $v:=1$ there are no singularities on $y^-$ because $\lim_{x\rightarrow0}y^-(x,1)=1$. This observation is used later, in \hyperref[step2]{Step 2}.
\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{plots/ch1_06_sols.pdf}
\caption{$y^+(x,v)$ and $y^-(x,v)$ for $v:= 0.8$.\label{fig:plotYs_1}}
\end{figure}
\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{plots/ch1_07_sols_1.pdf}
\caption{$y^+(x,v)$ and $y^-(x,v)$ for $v:=1$.\label{fig:plotYs_2}}
\end{figure}

The common domain of these two functions is the set 
$$
D_v:=\{x\in R:\, \Delta(x,v)\geq 0,\,x\neq 0\}.
$$ 
Notice that the only real root of the denominator is $x_0:=0$.\footnote{We checked with Laguerre's method, implemented with Python 2.7, that the polynomial $x^7+2x^4+x^3+x$ has 6 complex roots.} Let
$$
\gamma_v^+: D_v\to\R,\, x\mapsto\F(x,y^+(x,v))\quad\text{ and }\quad\gamma_v^-:D_v\to\R,\, x\mapsto\F(x,y^-(x,v))
$$
Note that $\F(\set{\G=v})=\text{im}(\gamma_v^+)\cup\text{im}(\gamma_v^-)$, so all reduce to prove the inclusion 
$$
(0,+\infty)\subset\text{im}(\gamma_v^+)\cup\text{im}(\gamma_v^-).
$$
\begin{center}
\fbox{\textbf{Step 2}} \emph{Main properties of $\gamma_v^+ \text{ and } \gamma_v^-$.}
\end{center}\label{step2}
In this section we are going to prove that:
$$
\text{(i)} \lim_{x\rightarrow \pm\infty}\gamma_v^+(x)=\lim_{x\rightarrow \pm\infty}\gamma_v^-(x)=0.
$$
$$\text{(ii)} \lim_{x\rightarrow 0}\gamma_v^+(x)=+\infty
,\quad \lim_{x\rightarrow 0}\gamma_v^-(x)=\left\{\begin{array}{ll}
+\infty&\text{ for $v\neq 1$}\\
 4 & \text{ for $v=1$}
\end{array} \right.
$$
Using Sage we can symbolically check how $\gamma_v^+\text{ and }\gamma_v^-$ look like, getting polynomials $A_1,A_2,B_1,B_2\in\R[x,v]$ and $C\in \R[x]$ such that:
$$\text{(a) }\gamma_v^+(x)=\dfrac{A_1(x,v)+B_1(x,v)\sqrt{\Delta(x,v)}}{C(x)}, \ \ 
\gamma_v^-(x)=\dfrac{A_2(x,v)+B_2(x,v)\sqrt{\Delta(x,v)}}{C(x)},$$
$$
\text{(b)}\ \ 
\arraycolsep=1.4pt\def\arraystretch{1.5}
\begin{array}{cclrl}
A_1(x,v)&=&\ \ A_2(x,v)\, , & \text{deg}_x(A_1)=\text{deg}_x(A_2)=24& \\
B_1(x,v)&=&-B_2(x,v)\, , &\text{deg}_x(B_1)=\text{deg}_x(B_2)=21& \\
C(x)&=&x^2(x^2+(x^3+1)^2)^4\, , & \text{deg}_x(C)=26&.
\end{array}
$$
We proceed to study $\gamma_v^+$ and $\gamma_v^-$ at the origin. Since $\Delta$ has even degree and positive leading coefficient with respect to $x$, it is positive for $\abs{x}$ large enough, so (i) holds.
			
Now, for $x=0$, we get $\Delta(0,v)=v>0$, thus $0\in\overline{D_v}$. Also:
\begin{itemize}
\item $A_1(0,v)+B_1(0,v) \sqrt{\Delta(0,v)}= v(1+\sqrt{v})^2>0$.
				\item $A_2(0,v)+B_2(0,v)\sqrt{\Delta(0,v)}=v(1-\sqrt{v})^2\geq 0$, and equality holds if and only if $v=1$.
\end{itemize}
			
\begin{figure}[h]
\centering
\includegraphics[width=0.75\textwidth]{plots/ch1_08_numerators.pdf}
\caption{Numerators of $\gamma_v^+$ and $\gamma_v^-$ for $x:=0$.\label{fig:numerators}}
\end{figure}
			
Thus, (ii) holds (we also checked it with Sage). The result for $v:=1$ in (ii) is not relevant here (see figure \ref{fig:limit}).
\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{plots/ch1_09_limit.pdf}
\caption{Notice the value of $\gamma_1^-(x)$ at $x=0$.\label{fig:limit}}
\end{figure}

\begin{center}
\fbox{\textbf{Step 3}} \emph{When $v\geq 0.28^2$ we have} $(0,+\infty)\subset\text{im}(\gamma_v^+)$.
\end{center}\label{step3}
In order to see whether $(0,+\infty)\subset\text{im}(\gamma_v^+)\cup\text{im}(\gamma_v^-)$ or not we are now going to study the domain $D_v$. To that end we need to study when $\Delta(x,v)=0$, so it seems convenient to define:
$$
v(x):=\frac{x^2(x+1)^2}{x^2+(x^3+1)^2},
$$
whose graph can be seen in figure \ref{fig:v(x)}. If $x\in(-\infty,0)$ we checked using Laguerre's method that the polynomial
\begin{figure}[h]\hspace{-0.2cm}
\begin{subfigure}{.5\linewidth}\centering
\includegraphics[width=1\textwidth]{plots/ch1_10_uve.pdf}
\caption{Plot of $v(x)$.\label{fig:uve}}
\end{subfigure}
\begin{subfigure}{.5\linewidth}\centering
\includegraphics[width=1\textwidth]{plots/ch1_11_uve_detail.pdf}
\caption{Detail of the function when $x\in(-4,0)$.\label{fig:uveDetail}}
\end{subfigure}\\[1ex]
\caption{Plot of the univariate function $v(x)$.\label{fig:v(x)}}
\end{figure}
$$
\Delta(x,0.28^2)=0.0784\,x^{6}-x^{4}-1.8432\,x^{3}-0.9216\,x^{2}+0.0784
$$ 
has 4 complex roots and 2 real ones\footnote{The value $v_0:=0.28^2$ comes from a careful observation of the plot from figure \ref{fig:uveDetail}.}. These last are $\delta_0\approx 0.236$ and $\delta_1\approx 4.336$. Thus $\Delta({\tt x},v)$ has no negative roots for $v\ge 0.28^2$ and, in addition, it only attains positive values. Therefore $(-\infty,0)\subset D_v$. But then, as $\gamma_v^+$ is continuous and recalling the limits computed in \hyperref[step2]{Step 2}, we get  
$$
(0,+\infty)\subset\text{im}(\gamma_v^+)\subset\text{im}(\gamma_v^+)\cup\text{im}(\gamma_v^-).
$$
\begin{center}
\fbox{\textbf{Step 4}} \emph{When $0<v<0.28^2$ we have} $(0,+\infty)\subset\text{im}(\gamma_v^-)$.
\end{center}
\label{step4}
To prove that for $0<v<0.28^2$ the inclusion $(0,+\infty)\subset\text{im}(\gamma_v^-)$ holds it is enough to prove the existence of $N_v,\delta_v\in\R$ satisfying			
\begin{equation*}\qquad \quad
\qquad\quad\boxed{N_v<\delta_v,\ \ (-\infty,N_v]\cup[\delta_v,+\infty)\subset D_v\text{ and } \gamma_v^-(N_v)>\gamma_v^+(\delta_v)\\
}\qquad \qquad (\spadesuit)
\end{equation*}
\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{plots/ch1_12_idea.pdf}
\caption{Idea of what we are saying with $(\spadesuit)$. Here $v:=0.1$.\label{fig:idea}}
\end{figure}
See figure \ref{fig:idea} to get an idea of what we are saying here. 

To prove the existence of such $N_v$ and $\delta_v$, we must compute the roots of $\Delta_v({\tt x})$ in an algebraic closure of the field of rational functions $\R(v)$. Such an algebraic closure is the field of Puiseux series $\C\left(\set{v^*}\right)$, see \ref{puiseux}. These roots are power series in $\C\left(\set{w^*}\right)$ with $w:=\sqrt{v}$, and we consider the largest and the smallest negative roots $\eta_v,\xi_v\in\R\left(\set{v^*}\right)$ of $\Delta_v$ with respect to the unique ordering in $\R\left(\set{v^*}\right)$ that makes $v$ positive and infinitesimal with respect to $\R$. These roots are:
			
\begin{equation*}\left\{\begin{split}
\eta_v:=&-\frac{1}{w}+1+w+w^2+\frac{5}{2}w^3+\cdots\\
\xi_v:=&-w-w^2-\frac{5}{2}w^3-6w^4+\cdots
\end{split}\right.
\end{equation*}
Notice that, by the definition of the ordering in $\R\left(\set{v^*}\right)$, the first coefficient of a series is the ``most meaningful orderwise". In particular $\eta_v<\xi_v$. To perform calculations, we handle suitable truncations of the involved series. Here the word suitable means ``as short as possible but order preserving"; in other words, we look for $N_v$ and $\delta_v$ with $N_v<\eta_v<\xi_v<\delta_v$, and in fact we choose
\begin{equation*}\left\{
\begin{split}
N_v:=&-\frac{1}{w}+1+w+w^2=\eta_v-\Big(\frac{5}{2}w^3+\cdots\Big)<\eta_v\\
\delta_v:=&-w-w^2-\frac{5}{2}w^3=\xi_v-(-6w^4+\cdots)>\xi_v
\end{split}\right.
\end{equation*}
We checked with Sage that $-\infty<N_v<\delta_v<0$ for $v\in (0,0.28^2)$ that is, for $w\in(0,0.28)$, see Figure \ref{fig:comp}. Now we can focus on proving $(\spadesuit)$. Since $\Delta(N_{w^2},w^2)$ and $\Delta(\delta_{w^2},w^2)$ are positive (see Figure \ref{fig:positive}) for $w\in (0,0.28)$, we get that $N_v, \delta_v\in D_v$.
\begin{figure}[h]\hspace{-0.25cm}
\begin{subfigure}{.50\linewidth}\centering
\includegraphics[width=1\textwidth]{plots/ch1_13_comp.pdf}
\caption{$-\infty<N_v<\delta_v<0$.\label{fig:comp}}
\end{subfigure}
\begin{subfigure}{.50\linewidth}\centering
\includegraphics[width=1\textwidth]{plots/ch1_14_positive.pdf}
\caption{$\Delta(N_{v}, v), \Delta(\delta_{v},v) > 0$.\label{fig:positive}}
\end{subfigure}\\[1ex]
\caption{Plots of $N_v,\delta_v<0$ and $\Delta(N_{v},v),\ \Delta(\delta_{v},v)>0$ for $v\in(0, 0.28^2)$.\label{fig:N_delta}}
\end{figure} For the first part, let 
$$
D:=\bigcup_{v>0}D_v=\bigcup_{v>0}\set{x\in\R:\Delta(x,v)\geq 0,\,x\neq 0},
$$ 
whose boundary is the union of the axis $\{x=0\}\subset\R^2$ and the curve given by the equation $\Delta(x,v)=0$, that is, the graph of the regular function
$$
v(x)=\frac{x^2(x+1)^2}{x^2+(x^3+1)^2}.
$$
This graph is above the axis $\{v=0\}\subset R^2$. Then, $(-\infty,N_v]$ and $[\delta_v,0)$ are contained in the interior of $D_v$ for $v\in (0, 0.28^2)$, because the curves 
$$
\set{(\delta_v,v):0<v<0.28^2}\, \, \, \text{and}\, \, \, \set{(N_v,v):0<v<0.28^2}
$$ 
are contained in $D$, they are graphs above the vertical axis $\{x=0\}\subset R^2$, and $\delta_v<\xi_v$ and $N_v<\eta_v$ as we saw before. Look at figure \ref{fig:nice_plot}.

\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{plots/ch1_15_nice_plot.pdf}
\caption{Plot of $\set{(N_v,v)}, \set{(\delta_v,v)}\subset D_v$, for $0<v<0.28^2$.\label{fig:nice_plot}}
\end{figure}
So the only thing left to do is checking that $\gamma_v^-(N_v)>\gamma_v^-(\delta_v)$. Recall that 
$$
\gamma_v^-({\tt x})=\dfrac{A_2({\tt x},v)+B_2({\tt x},v)\sqrt{\Delta({\tt x},v)}}{C({\tt x})},
$$
with $\text{deg}_{\tt x}(A_2)=24,\, \, \text{deg}_{\tt x}(B_2)=21,\, \, \text{deg}_{\tt x}(\Delta)=6\, \, \text{ and }\text{deg}_{\tt x}(C)=26$. Consider:
$$
\arraycolsep=2pt\def\arraystretch{1.5}
\begin{array}{rclcrcl}
\cdot\ f_1(w)&=&A_2(N_{w^2},w^2)\cdot w^{24}& \qquad &\cdot\ f_2(w)&=& A_2(\delta_{w^2},w^2)\\
\cdot\ g_1(w)&=&B_2(N_{w^2},w^2)\cdot w^{21}& \qquad &\cdot\ g_2(w)&=&B_2(\delta_{w^2},w^2)\\
\cdot\ q_1(w)&=&\Delta(N_{w^2},w^2)& \qquad &\cdot\ q_2(w)&=&\Delta(\delta_{w^2},w^2)\\
\cdot\ h_1(w)&=&C(N_{w^2})\cdot w^{26}& \qquad &\cdot\ h_2(w)&=&C(\delta_{w^2}).
\end{array}
$$
Thus, we need to prove that for $w\in(0,0.28)$:
$$
\frac{f_1\cdot(w^{24})^{-1}+g_1\cdot (w^{21})^{-1}\sqrt{q_1}}{h_1\cdot(w^{26})^{-1}}>\frac{f_2+g_2\sqrt{q_2}}{h_2} \iff
$$
$$
\frac{w^2h_2f_1-f_2h_1}{h_1h_2}+\frac{w^5g_1\sqrt{q_1}}{h_1}-\frac{g_2\sqrt{q_2}}{h_2}>0,
$$
and we are going to prove that 
$$
\Lambda_1:= \frac{w^2h_2f_1-f_2h_1}{h_1h_2},\, \, \, \Lambda_2:=\frac{w^5g_1\sqrt{q_1}}{h_1} \, \text{ and } \Lambda_3 := -\frac{g_2\sqrt{q_2}}{h_2}
$$
are positive in the given interval, which only contains positive values. As $q_1,q_2$ are positive, we can clear away $w^5$ and $\sqrt{q_1}$ from $\Lambda_2$, and $\sqrt{q_2}$ from $\Lambda_3$. Furthermore, the polynomial $C({\tt x})={\tt x}^2({\tt x}^2+({\tt x}^3+1)^2)^4>0$, so we can also remove $h_1$ and $h_2$ from $\Lambda_1,\Lambda_2, \Lambda_3$. Thus it suffices to see that
$$
L:=\frac{w^2h_2f_1-f_2h_1}{w^4},\quad g_1,\quad K:=-\frac{g_2}{w^3}
$$ 
are positive for $w\in(0,0.28)$.

\vspace{2cm}

As we see in the figures they indeed are. This has been also checked with Sturm algorithm and numerically with Sage. Thus, $(\spadesuit)$ holds and the result is proved.

\begin{center}
\includegraphics[width=0.45\linewidth]{plots/ch1_16_L.pdf}
\includegraphics[width=0.45\linewidth]{plots/ch1_17_g_1.pdf} \\
\includegraphics[width=0.45\linewidth]{plots/ch1_18_K.pdf}		
\end{center}
\qed
\end{section}
\end{chapter}

\begin{chapter}{A short proof for the open quadrant $\Qu$ problem}
\begin{section}{A new approach}
In the previous chapter, we proved that $\Qu$ is the image of $\R^2$ under the polynomial map $\P:=(\F,\G)$. This fact alongside Theorem \ref{finSetTh} were key for proving Theorem \ref{openQuadGen}. To achieve Theorem \ref{openQuad}, we needed the aid of a computer in order to check that certain polynomials do not have roots on particular intervals or that they are positive on them. Although legit, this procedure is controversial, and the authors kept on working on the problem of characterizing which semialgebraic subsets $\mathscr{S} \subset \R^m$ are polynomial images of $\R^n$ and wrote a new paper (\cite{fu}) with a much simpler proof.

In this third chapter we present a new approach to the open quadrant problem. We will show that $\Qu$ is the image of the composition of three simple polynomial maps: $\FF,\, \GG \text{ and } \HH$. The proof of Theorem \ref{openQuad} will be conducted by inspecting at the images of the aforementioned polynomials, albeit the lack of precise tools to determine the image of a polynomial map.

\begin{subsection}{The new polynomial maps}
In this subsection we introduce new polynomial maps that satisfy the requirements to prove Theorem \ref{openQuad} in a different way. To be more precise, we define 
$$
f:=\HH\circ\GG\circ\FF:\R^2\longrightarrow \R^2,
$$
where
\begin{equation*}
\boxed{
\begin{aligned}
\FF:\R^2\longrightarrow \R^2,\ (x,y)&\longmapsto((xy-1)^2+x^2,\ (xy-1)^2+y^2), \\
\GG:\R^2\longrightarrow \R^2,\ (x,y)&\longmapsto(x,\ y(xy-2)^2+x(xy-1)^2), \\
\HH:\R^2\longrightarrow \R^2,\ (x,y)&\longmapsto(x(xy-2)^2+\tfrac{1}{2}xy^2,\ y). \\
\end{aligned}
}
\end{equation*}
We can see how the graphs of the components of these maps look like in figure \ref{fig:ch2Maps}, and appreciate the symmetry between the $x$ and $y$ variables while the transformation is performed.

In the next section we proceed to develop the proof, which splits into three lemmas.

\begin{figure}
\hspace{-0.1cm}
\begin{subfigure}{.49\linewidth}\centering
\begin{tikzpicture}
\node[anchor=south west,inner sep=0] (img)at (0,0) {\includegraphics[width=1\textwidth]{plots/ch2_01_F_1.png}};
\path ($(img.north west)!0.28!(img.north east)$)|-coordinate(c1)($(img.south east)!0.1!(img.north east)$);
\path ($(img.north west)!0.85!(img.north east)$)|-coordinate(c2)($(img.south east)!0.15!(img.north east)$);
\draw (c1) node {$x$};
\draw (c2) node {$y$};
\end{tikzpicture}
\vspace{0.15cm}\caption{$\FF_1({\tt x},{\tt y})=({\tt x}{\tt y}-1)^2+{\tt x}^2$.\label{fig:FF_1}}
\end{subfigure}
\begin{subfigure}{.49\linewidth}\centering
\begin{tikzpicture}
\node[anchor=south west,inner sep=0] (img)at (0,0){\includegraphics[width=1\textwidth]{plots/ch2_02_F_2.png}};
\path ($(img.north west)!0.28!(img.north east)$)|-coordinate(c1)($(img.south east)!0.1!(img.north east)$);
\path ($(img.north west)!0.85!(img.north east)$)|-coordinate(c2)($(img.south east)!0.15!(img.north east)$);
\draw (c1) node {$x$};
\draw (c2) node {$y$};
\end{tikzpicture}
\vspace{0.15cm}\caption{$\FF_2({\tt x},{\tt y})=({\tt x}{\tt y}-1)^2+{\tt y}^2$.\label{fig:FF_2}}
\end{subfigure}\\[1ex]
\vspace{0.4cm}
	
\hspace{-0.1cm}
\begin{subfigure}{.49\linewidth}\centering
\begin{tikzpicture}
\node[anchor=south west,inner sep=0] (img)at (0,0) {\includegraphics[width=1\textwidth]{plots/ch2_03_G_1.png}};
\path ($(img.north west)!0.67!(img.north east)$)|-coordinate(c1)($(img.south east)!0.055!(img.north east)$);
\path ($(img.north west)!0.72!(img.north east)$)|-coordinate(c2)($(img.south east)!0.26!(img.north east)$);
\draw (c1) node {$x$};
\draw (c2) node {$y$};
\end{tikzpicture}
\vspace{0.15cm}\caption{$\GG_1({\tt x}, {\tt y}) = {\tt x}$.\label{fig:GG_1}}
\end{subfigure}
\begin{subfigure}{.49\linewidth}\centering
\begin{tikzpicture}
\node[anchor=south west,inner sep=0] (img)at (0,0) {\includegraphics[width=1\textwidth]{plots/ch2_04_G_2.png}};
\path ($(img.north west)!0.2!(img.north east)$)|-coordinate(c1)($(img.south east)!0.15!(img.north east)$);
\path ($(img.north west)!0.81!(img.north east)$)|-coordinate(c2)($(img.south east)!0.14!(img.north east)$);
\draw (c1) node {$x$};
\draw (c2) node {$y$};
\end{tikzpicture}
\vspace{0.15cm}\caption{$\GG_2({\tt x},{\tt y})={\tt y}({\tt x}{\tt y}-2)^2+{\tt x}({\tt x}{\tt y}-1)^2$.\label{fig:GG_2}}
\end{subfigure}\\[1ex]
\vspace{0.4cm}

\hspace{-0.1cm}
\begin{subfigure}{.49\linewidth}\centering
\begin{tikzpicture}
\node[anchor=south west,inner sep=0] (img)at (0,0) {\includegraphics[width=1\textwidth]{plots/ch2_05_H_1.png}};
\path ($(img.north west)!0.29!(img.north east)$)|-coordinate(c1)($(img.south east)!0.08!(img.north east)$);
\path ($(img.north west)!0.85!(img.north east)$)|-coordinate(c2)($(img.south east)!0.14!(img.north east)$);
\draw (c1) node {$x$};
\draw (c2) node {$y$};
\end{tikzpicture}
\vspace{0.15cm}\caption{$\HH_1({\tt x},{\tt y})={\tt x}({\tt x}{\tt y}-2)^2+\tfrac{1}{2}{\tt x}{\tt y}^2$.\label{fig:HH_1}}
\end{subfigure}
\begin{subfigure}{.49\linewidth}\centering
\begin{tikzpicture}
\node[anchor=south west,inner sep=0] (img)at (0,0) {\includegraphics[width=1\textwidth]{plots/ch2_06_H_2.png}};
\path ($(img.north west)!0.2!(img.north east)$)|-coordinate(c1)($(img.south east)!0.1!(img.north east)$);
\path ($(img.north west)!0.78!(img.north east)$)|-coordinate(c2)($(img.south east)!0.11!(img.north east)$);
\draw (c1) node {$x$};
\draw (c2) node {$y$};
\end{tikzpicture}
\vspace{0.15cm}\caption{$\HH_2({\tt x},{\tt y})={\tt y}$.\label{fig:HH_2}}
\end{subfigure}
\vspace{0.7cm}\caption{The polynomial maps from the second proof: $(\HH\circ\GG\circ\FF)(\R^2)=\Qu$.\label{fig:ch2Maps}}
\end{figure}
\end{subsection}
\end{section}

\begin{section}{The new proof for the open quadrant problem}
As we have anticipated before, $\Qu$ is the image of the composition $\HH\circ\GG\circ \FF$, but before proving this fact we need three auxiliar lemmas in order to shed some light on the properties that the images of $\FF,\,\GG\text { and }\HH$ enjoy.

\begin{subsection}{The first lemma}
\begin{lemma}\label{lemma1}
Let $\mathscr{A}:=\set{xy\ge1}\ \cap\, \Qu$. Then the image of the map
$$
\FF:=(\FF_1,\FF_2):\R^2\to\R^2,(x,y)\mapsto((xy-1)^2+x^2,(xy-1)^2+y^2)
$$
satisfies that $\mathscr{A}\subset\FF(\R^2)\subset\Qu$.
\begin{Proof}
Since $\FF_1$ and $\FF_2$ are positive on $\R^2$, the inclusion $\FF(\R^2) \subset \Qu$ is evident. To prove the other inclusion, we must show that for $(a,b)\in\mathscr{A}$ the system of polynomial equations
\begin{equation}\label{eq:systemF}
\left\{
\begin{aligned}
({\tt x}{\tt y}-1)^2+{\tt x}^2=a\\
({\tt x}{\tt y}-1)^2+{\tt y}^2=b\\
\end{aligned}
\right.
\end{equation}
has a solution $(x_0,y_0)\in\R^2$. Set ${\tt z}:={\tt x}{\tt y}-1$ in order to rewrite the system \ref{eq:systemF} in terms of ${\tt x}$ and ${\tt z}$. Since ${\tt y}=\frac{{\tt z}+1}{{\tt x}}$ we get:
\begin{equation}\label{eq:system2F}
\left\{
\begin{aligned}
&{\tt z}^2+{\tt x}^2&=a\\
&{\tt z}^2+\frac{({\tt z}+1)^2}{{\tt x}^2}&=b&.\\
\end{aligned}
\right.
\end{equation}
By eliminating ${\tt x}$ on the system \ref{eq:system2F} we deduce that ${\tt z}$ must be a root of the polynomial
$$
P({\tt z}):={\tt z}^4-(a+b+1){\tt z}^2-2{\tt z}+(ab-1)=0.
$$
Taking into account that $(a,b)\in\mathscr{A}$ satisfy that $a,b>0$ and $ab\ge1$, we notice that $P$ is a monic polynomial of even degree satisfying
$$
P(0)=ab-1\ge0\quad\text{ and }\quad P(\sqrt{a})=-2\sqrt{a}-a-1<0.
$$
Thus, $P$ has a real root $z_0$ such that $0\le z_0<\sqrt{a}$, so we set:
$$
x_0:=\sqrt{a-z_0^2}\quad \text{ and } \quad y_0:= \frac{z_0+1}{x_0}.
$$
Then $F(x_0,y_0)=(a,b)$ and $\mathscr{A}\subset\FF(\R^2)$, as required.
\qed
\end{Proof}
\end{lemma}
\end{subsection}

\begin{figure}[h]
\begin{subfigure}{.5\linewidth}\centering
\begin{tikzpicture}
\node[anchor=south west,inner sep=0] (img)at (0,0) {\includegraphics[width=1\textwidth]{plots/ch2_07_A.pdf}};
\path ($(img.north west)!0.6!(img.north east)$)|-coordinate(c1)($(img.south east)!0.7!(img.north east)$);% c1: lugar donde poner \mathscr{A}
\draw (c1) node {\huge{$\mathscr{A}$}};
\end{tikzpicture}
\caption{$\mathscr{A}=\set{xy\ge 1}\ \cap\, \Qu$.\label{fig:setA}}
\end{subfigure}
\hspace{-0.2cm}
\begin{subfigure}{.5\linewidth}\centering
\begin{tikzpicture}
\node[anchor=south west,inner sep=0] (img)at (0,0) {\includegraphics[width=1\textwidth]{plots/ch2_08_B.pdf}};
\path ($(img.north west)!0.6!(img.north east)$)|-coordinate(c1)($(img.south east)!0.7!(img.north east)$);% c1: lugar donde poner \mathscr{B}
\draw (c1) node {\huge{$\mathscr{B}$}};
\end{tikzpicture}
\caption{$\mathscr{B}=\mathscr{A}\cup\set{y\ge x>0}$.\label{fig:setB}}
\end{subfigure}
\caption{Relevant sets for Lemmas \ref{lemma1}, \ref{lemma2} and \ref{lemma3}.\label{fig:setsAB}}
\end{figure}

\begin{subsection}{The second lemma}
\begin{lemma}\label{lemma2}
Let $\mathscr{B}:=\mathscr{A}\cup\set{y\ge x>0}$. Then, the map
$$
\GG:=(\GG_1,\GG_2):\R^2\to\R^2,(x,y)\mapsto (x,\ y(xy-2)^2+x(xy-1)^2)
$$
satisfies that $\mathscr{B}\subset\GG(\mathscr{A})\subset\GG(\Qu)\subset\Qu$.
\begin{Proof}
The inclusion $\GG(\mathscr{A}) \subset \GG(\Qu)$ is trivial because $\mathscr{A}\subset\Qu$. The last inclusion $\GG(\Qu) \subset\Qu$ also holds since $\GG_1$ and $\GG_2$ are strictly positive on $\Qu$: if $x_0,y_0>0$ then $\GG_1(x_0,y_0)=x_0> 0$ and $\GG_2(x_0,y_0)=y_0(x_0y_0-2)^2+x_0(x_0y_0-1)^2>0$. Notice that $\GG_2(x_0,y_0)\ne0$. Otherwise there would exists a solution of the system of equations
\begin{equation*}
\left\{
\begin{aligned}
&{\tt x}{\tt y}-1=0\\
&{\tt x}{\tt y}-2=0,\\
\end{aligned}
\right.
\end{equation*}
which is not possible.

Now we can focus on proving $\mathscr{B} \subset \GG(\mathscr{A})$. First of all, notice that we can express the set $\mathscr{B}$ as a union of closed half-lines. Precisely, for each $x>0$ let $\mathscr{B}_x:=[y_x,+\infty)$, where $y_x:=\text{min}\set{x,1/x}$ and notice that
$$
\mathscr{B}=\bigsqcup_{x>0}(\set{x}\times\mathscr{B}_x).
$$
That is, we are ``slicing'' the set $\mathscr{B}$ vertically, depending on $x$. Now look at the definition of the polynomial $\GG_2$ and consider for each $x>0$ the polynomial $\phi_x\in\R[{\tt y}]$ (dependent on the variable ${\tt y})$:
$$
\phi_x({\tt y}):={\tt y}(x{\tt y}-2)^2+x(x{\tt y}-1)^2=x^2{\tt y}^3+(x^3-4x){\tt y}^2+(4-2x^2){\tt y}+x.
$$
The polynomials $\phi_x({\tt y})$ have odd degree and positive leading coefficient since $x > 0$. Now notice that if we fix $x_0 > 0$ then we get the following sequence of inclusions:
\begin{equation*}
\begin{aligned}
\phi_{x_0}(&[1/x_0,+\infty))\ \supset ^1 \ \phi_{x_0}([2/x_0,+\infty))\\
&\quad \quad \ \rotatebox[origin=c]{90}{$\subset$}\,^2 \hspace{3cm} \rotatebox[origin=c]{90}{$\subset$}\,^3\\
&[1/x_0,+\infty) \hspace{1.9cm}[x_0, +\infty) \\
\end{aligned}
\end{equation*}
Inclusion $^1$ follows from the fact that $[1/x_0, +\infty) \supset [2/x_0, +\infty)$ (notice that for $x>0$ the graph of the map $2/x$ is ``above'' the one of $1/x$). Inclusion $^2$ and $^3$ follow from the fact that $\phi_{x_0}({\tt y})$ has positive leading coefficient and the computation of the images of $1/x_0$ and $2/x_0$ through $\phi_{x_0}({\tt y})$:
\begin{equation*}
\begin{aligned}
\phi_{x_0}\left(\frac{1}{x_0}\right)&=\frac{1}{x_0}+\left((x_0^3-4x_0)\frac{1}{x_0^2}+(4-2x_0^2)\frac{1}{x_0}+x_0\right)= \frac{1}{x_0}\\
\phi_{x_0}\left(\frac{2}{x_0}\right)&=\left(\frac{8}{x_0}+(x_0^3-4x_0)\frac{4}{x_0^2}+(4-2x_0^2)\frac{2}{x_0}\right)+x_0= x_0.\\
\end{aligned}
\end{equation*}
Now it is clear that:
$$
\mathscr{B}_x=[y_x,+\infty)\subset\phi_x([1/x, +\infty)).
$$
Then we can prove the desired inclusion in this way:
$$
\mathscr{B}=\bigsqcup_{x>0}\big(\set{x}\times\mathscr{B}_x\big)\subset\bigsqcup_{x>0}\big(\set{x}\times\phi_x([1/x,+\infty))\big)=\bigsqcup_{x>0}\GG\big(\set{x}\times[1/x,+\infty)\big)=\GG(\mathscr{A}),
$$
which concludes the proof.
\qed
\end{Proof}
\end{lemma}
\end{subsection}

\begin{center}
\begin{figure}[h]
\begin{subfigure}{.49\linewidth}\centering
\begin{tikzpicture}
\node[anchor=south west,inner sep=0] (img)at (0,0) {\includegraphics[width=1\textwidth]{plots/ch2_09_B_vert.pdf}};
\path ($(img.north west)!0.8!(img.north east)$)|-coordinate(c1)($(img.south east)!0.8!(img.north east)$); % Para \mathscr{B}
\path ($(img.north west)!0.1!(img.north east)$)|-coordinate(c2)($(img.south east)!0.89!(img.north east)$); % Para la flecha de x_0
\path ($(img.north west)!0.613!(img.north east)$)|-coordinate(c3)($(img.south east)!0.89!(img.north east)$); % Para la flecha de x_1
\path ($(img.north west)!0.1!(img.north east)$)|-coordinate(c4)($(img.south east)!0.105!(img.north east)$); % Para [
\path ($(img.north west)!0.613!(img.north east)$)|-coordinate(c5)($(img.south east)!0.101!(img.north east)$); % Para [
\path ($(img.north west)!0.1!(img.north east)$)|-coordinate(c6)($(img.south east)!0.01!(img.north east)$); % Para x_0
\path ($(img.north west)!0.613!(img.north east)$)|-coordinate(c7)($(img.south east)!0.01!(img.north east)$); % Para x_1
\path ($(img.north west)!0.26!(img.north east)$)|-coordinate(c8)($(img.south east)!0.55!(img.north east)$); % Para B_{x_0}
\path ($(img.north west)!0.77!(img.north east)$)|-coordinate(c9)($(img.south east)!0.35!(img.north east)$); % Para B_{x_1}
\draw (c1) node {\huge{$\mathscr{B}$}};
\draw (c2) node {\Large{\color[rgb]{0,0.392157,0}{$\uparrow$}}};
\draw (c3) node {\Large{\color[rgb]{1,0,0}{$\uparrow$}}};
\draw (c4) node {\large{\color[rgb]{0,0.392157,0}{\rotatebox[origin=c]{90}{[}}}};
\draw (c5) node {\large{\color[rgb]{1,0,0}{\rotatebox[origin=c]{90}{[}}}};
\draw (c6) node {\large{\color[rgb]{0,0.392157,0}{$x_0$}}};
\draw (c7) node {\large{\color[rgb]{1,0,0}{$x_1$}}};
\draw (c8) node {\large{\color[rgb]{0,0.392157,0}{$\set{x_0} \times \mathscr{B}_{x_0}$}}};
\draw (c9) node {\large{\color[rgb]{1,0,0}{$\set{x_1} \times \mathscr{B}_{x_1}$}}};
\end{tikzpicture}
\caption{$\mathscr{B} = \bigsqcup_{x>0}(\set{x} \times \mathscr{B}_{x})$.\label{fig:Bvert}}
\end{subfigure}
\begin{subfigure}{.49\linewidth}\centering
\begin{tikzpicture}
\node[anchor=south west,inner sep=0] (img)at (0,0) {\includegraphics[width=1\textwidth]{plots/ch2_10_B_hor.pdf}};
\path ($(img.north west)!0.6!(img.north east)$)|-coordinate(c1)($(img.south east)!0.7!(img.north east)$);% c1: lugar donde poner \mathscr{B}
\path ($(img.north west)!0.8!(img.north east)$)|-coordinate(c1)($(img.south east)!0.8!(img.north east)$); % Para \mathscr{B}
\path ($(img.north west)!0.9!(img.north east)$)|-coordinate(c2)($(img.south east)!0.604!(img.north east)$); % Para la flecha de y_0
\path ($(img.north west)!0.9!(img.north east)$)|-coordinate(c3)($(img.south east)!0.1492!(img.north east)$); % Para la flecha de y_1
\path ($(img.north west)!0.045!(img.north east)$)|-coordinate(c4)($(img.south east)!0.61!(img.north east)$); % Para (
\path ($(img.north west)!0.045!(img.north east)$)|-coordinate(c5)($(img.south east)!0.154!(img.north east)$); % Para (
\path ($(img.north west)!0.146!(img.north east)$)|-coordinate(c10)($(img.south east)!0.154!(img.north east)$); % Para ]
\path ($(img.north west)!0.335!(img.north east)$)|-coordinate(c11)($(img.south east)!0.154!(img.north east)$); % Para [
\path ($(img.north west)!0.008!(img.north east)$)|-coordinate(c6)($(img.south east)!0.61!(img.north east)$); % Para y_0
\path ($(img.north west)!0.008!(img.north east)$)|-coordinate(c7)($(img.south east)!0.154!(img.north east)$); % Para y_1
\path ($(img.north west)!0.25!(img.north east)$)|-coordinate(c8)($(img.south east)!0.66!(img.north east)$); % Para B_{y_0}
\path ($(img.north west)!0.65!(img.north east)$)|-coordinate(c9)($(img.south east)!0.2!(img.north east)$); % Para B_{y_1}
\draw (c1) node {\huge{$\mathscr{B}$}};
\draw (c2) node {\Large{\color[rgb]{0,0.392157,0}{$\rightarrow$}}};
\draw (c3) node {\Large{\color[rgb]{1,0,0}{$\rightarrow$}}};
\draw (c4) node {\large{\color[rgb]{0,0.392157,0}{(}}};
\draw (c5) node {\large{\color[rgb]{1,0,0}{(}}};
\draw (c10) node {\large{\color[rgb]{1,0,0}{]}}};
\draw (c11) node {\large{\color[rgb]{1,0,0}{[}}};
\draw (c6) node {\large{\color[rgb]{0,0.392157,0}{$y_0$}}};
\draw (c7) node {\large{\color[rgb]{1,0,0}{$y_1$}}};
\draw (c8) node {\large{\color[rgb]{0,0.392157,0}{$\mathscr{C}_{y_0} \times \set{y_0}$}}};
\draw (c9) node {\large{\color[rgb]{1,0,0}{$\mathscr{C}_{y_1} \times \set{y_1}$}}};
\end{tikzpicture}
\caption{$\mathscr{B}=\bigsqcup_{y>0}(\mathscr{C}_{y}\times\set{y})$.\label{fig:Bhor}}
\end{subfigure}
\caption{Idea of how we represent the set $\mathscr{B}$ in Lemmas \ref{lemma2} and \ref{lemma3}.\label{fig:sliceB}}
\end{figure}
\end{center}

\begin{subsection}{The third lemma}
\begin{lemma}\label{lemma3}
The polynomial map 
$$
\HH:=(\HH_1,\HH_2):\R^2\to\R^2,(x,y)\mapsto(x(xy-2)^2+\tfrac{1}{2}xy^2,\ y)
$$
satisfies $\HH(\mathscr{B})=\HH(\Qu)=\Qu$.
\begin{Proof}
The inclusion $\HH(\mathscr{B})\subset\HH(\Qu)$ is trivial because $\mathscr{B}\subset\Qu$. As for $\HH(\Qu)\subset\Qu$, since $\HH_1$ and $\HH_2$ are strictly positive on $\Qu$ the inclusion holds.

We proceed now to prove that $\Qu\subset\HH(\mathscr{B})$ and therefore get $\Qu\subset\HH(\mathscr{B})\subset\HH(\Qu) \subset\Qu$, which implies that $\HH(\mathscr{B})=\HH(\Qu)=\Qu$.

Firstly, notice that the set $\mathscr{B}$ can be expressed as follows:
$$
\mathscr{B}=\bigsqcup_{y>0}(\mathscr{C}_y\times\set{y}),\quad\text{ where } \mathscr{C}_y:= 
\left\{
\begin{array}{ll}
(0,+\infty)&\text{ if } y \ge 1,\\
(0,y]\cup[1/y,+\infty) & \text { if } 0<y<1.
\end{array}
\right.
$$
Intuitively, we are ``slicing'' the set $\mathscr{B}$ horizontally, depending on $y$. Looking at the definition of $\HH_1$ we define for each $y>0$ the polynomial $\psi_y$ dependent on the variable ${\tt x}$:
$$
\psi_y({\tt x}):={\tt x}(y{\tt x}-2)^2+\tfrac{1}{2}y^2{\tt x}=y^2{\tt x}^3-4y{\tt x}^2+(4+\tfrac{1}{2}y^2){\tt x}.
$$
Notice first that $\psi_y({\tt x})$ has odd degree, positive leading coefficient and the following properties:
$$
\begin{array}{llcll}
\text{(i)}&\lim_{x\rightarrow+\infty}\psi_y(x)=+\infty. & &
\text{(iii)}&\psi_y(y)=y((y^2-2)^2+\tfrac{1}{2}y^2)>y\text{ for } 0<y<1.\\
\text{(ii)}&\psi_y(0)=0. & &
\text{(iv)}&\psi_y\left(\tfrac{2}{y}\right)=y.\\
\end{array}
$$
Property (iii) holds because $(y^2-2)^2+\tfrac{1}{2}y^2>1$ when $0<y<1$. Next, we are going to show that:
$$
\!\psi_y(\mathscr{C}_y) \!=\!
\left\{ \def\arraystretch{1.5}
\begin{array}{ll} 
\! \! \psi_y((0,+\infty))=^1(0,+\infty) & \!\!\! \text{ if } y \ge 1,\\
\! \! \psi_y\big((0,y]\cup \big[\frac{1}{y}, +\infty\big)\big) \supset^2 (0, \psi_y(y)] \cup \big[\psi_y\big(\tfrac{2}{y}\big),+\infty\big)=^3(0,+\infty)& \!\!\! \text{ if } 0<y<1.
\end{array}
\right.
$$
Equality $^1$ holds because of (i), (ii) and the fact that $\psi_y$ is strictly positive on $(0, +\infty)$. Inclusion $^2$  follows from the fact that $[1/y_0,+\infty)\supset[2/y_0,+\infty)$ for each fixed $y_0$. Finally, equality $^3$ holds because of (iii) and (iv): $\psi_y(y) > y = \psi_y\big(\tfrac{2}{y}\big)$.

Then we can write:
$$
\Qu=\bigsqcup_{y>0}\big((0,+\infty)\times\set{y}\big)\subset \bigsqcup_{y>0}\big(\psi_y(\mathscr{C}_y)\times\set{y}\big)= \bigsqcup_{y>0}\HH\big(\mathscr{C}_y\times\set{y}\big)=\HH(\mathscr{C}_y),
$$
which concludes the proof.
\qed
\end{Proof}
\end{lemma}
\end{subsection}

\begin{subsection}{The second proof for the open quadrant problem}
To wrap up this chapter, we can now write the proof of Theorem \ref{openQuad} relying on Lemmas \ref{lemma1}, \ref{lemma2} and \ref{lemma3}:

\vspace{1mm}

[Proof of Theorem \ref{openQuad}] Applying the lemmas, we deduce that
$$
\Qu \overset{\ref{lemma3}}{=}\HH(\mathscr{B})\overset{\ref{lemma2}}{\subset}(\HH\circ\GG)(\mathscr{A}) \overset{\ref{lemma1}}{\subset}(\HH\circ\GG\circ\FF)(\R^2)\overset{\ref{lemma1}}{\subset}(\HH\circ\GG)(\Qu) \overset{\ref{lemma2}}{\subset}\HH(\Qu)\overset{\ref{lemma3}}{=}\Qu,
$$
which means 
$$
(\HH\circ\GG\circ\FF)(\R^2)=\Qu,
$$
as required.
\qed
\end{subsection}


%%Ejemplo de como introducir texto con TikZ, con una rejilla de ayuda
%--------------------------------------------------------------------%
%\begin{figure}[h]
%\begin{tikzpicture}
%\node[anchor=south west,inner sep=0] (img)at (0,0) {\includegraphics[width=\textwidth]{plots/ch1_15_nice_plot.pdf}};
%\foreach \xx in {0,1,2,...,9}{
%\draw[dashed] ($(img.north west)!0.\xx!(img.north east)$)node[above]{0.\xx} --  ($(img.south west)!0.\xx!(img.south east)$);
%\draw[dashed] ($(img.south east)!0.\xx!(img.north east)$)node[right]{0.\xx} --  ($(img.south west)!0.\xx!(img.north west)$);
%}
%\path ($(img.north west)!0.1!(img.north east)$)|-coordinate(c1)($(img.south east)!0.3!(img.north east)$);% c1: first corner
%\path ($(img.north west)!0.82!(img.north east)$)|-coordinate(c2)($(img.south east)!0.77!(img.north east)$);   %c2 : second corner
%\draw[red,ultra thick,rounded corners] (c1)         rectangle (c2);
%\draw (c1) node {\huge{$\mathscr{A}$}};
%\draw (c2) node[below] {\huge{$\mathscr{B}$}};
%\end{tikzpicture}
%\caption{M1} \label{fig:M1}
%\end{figure}
%--------------------------------------------------------------------%

\end{section}
\end{chapter}

\begin{chapter}{A topological proof for the open quadrant $\Qu$ problem}
\begin{section}{A topological perspective}
%Modificad cualquier cosa que no os convenza o que no sea totalmente cierta de esta introduccion:
Not happy with having proved that $\Qu$ is the image of $\R^2$ under two different polynomial maps using diverse techniques, the authors developed a whole new proof that relies on algebraic topology for a new polynomial map $\FFF: \R^2 \longrightarrow \R^2$. The genesis of this work was their collaboration with C. Ueno while he was writing his Ph.D. Thesis \cite{u}.

In this chapter we will build up the topological machinery that will allow us to prove theorem \ref{openQuad} in a very geometrical way, and completely avoiding the aid of computer calculations.
\begin{subsection}{The new polynomial map}
Without further ado, the polynomial map we are going to be working with is $\FFF$ defined in the following way:
\begin{equation*}
\boxed{
\FFF({\tt x}, {\tt y}) := \big(({\tt x}^2{\tt y}^4+{\tt x}^4{\tt y}^2-{\tt y}^2-1)^2+{\tt x}^6{\tt y}^4,\ ({\tt x}^6{\tt y}^2+{\tt x}^2{\tt y}^2-{\tt x}^2-1)^2+{\tt x}^6{\tt y}^4\big).
}
\end{equation*}

As we anticipated before, in the next section we will give some topological definitions and proof some facts about a family of topological spaces homeomorphic to a closed disc in $\R^3$, and paths that go through them.

Afterwards, by decomposing $\FFF$ into the composition $\FFF = f_2 \circ (h \circ g)$, it will be clear that we can reduce the proof to check that the boundaries of two certain topological spaces (homeomorphic to a closed disc) have non-empty intersection with the image $g(\overline{\Qu})$, where $\overline{\Qu} = \set{x \ge 0, y \ge 0}$ is the closure of the open quadrant $\Qu$.
\end{subsection}
\end{section}
\begin{section}{Topological tools}
\begin{subsection}{Some definitions}
We begin by defining the key topological varieties we are going to be working with:
\begin{definitions}
(i) Let ${\mathbb D}_A = \set{(x,y): x^2+y^2 \le A^2} \subset \R^2$ be the closed disc of center the origin and radius $A>0$. A \textit{warped disc} is a subset 
$$\D_{A,\xi}:=\set{(x,y,z): x^2+y^2\le A^2,\ z=\xi(x,y)}\subset\R^3$$
where $\xi:\R^2\longrightarrow\R$ is a continuous function. Let $\zeta$ be the homeomorphism
$$
\zeta:\R^3\longrightarrow\R^3,\ (x,y,z)\longmapsto\big(x,\, y,\, z-\xi(x,y)\big).
$$
Then, it is clear that $\zeta(\D_{A,\xi}) = {\mathbb D}_A\times\{0\}$. We will also call a warped disc the image of $\D_{A,\xi}$ under a permutation of the variables of $\R^3$:
\begin{equation*}
\begin{aligned}
\D_{A,\xi}:=\set{(x,y,z): y^2+z^2\le A^2,\ x=\xi(y,z)}& \ \text{ or } \\
\D_{A,\xi}:=\set{(x,y,z): x^2+z^2\le A^2,\ y=\xi(x,z)}&,
\end{aligned}
\end{equation*}
with $\xi$ defined as above.

(ii) For each $\eps>0$ let us define the open neighborhood of ${\mathbb D}_A$
$$
{\mathbb D}_A(\eps):=\set{(x,y):x^2+y^2<(A+\eps)^2}\times(-\eps,\eps)\subset\R^3.
$$ 
Clearly, in this way we obtain an open neighborhood of $\D_{A,\xi}$ by defining 
$$
\D_{A,\xi}(\eps):=\zeta^{-1}\big({\mathbb D}_A(\eps)\big) \subset \R^3,
$$
which is guaranteed to be well-defined because $\zeta$ is an homeomorphism.
\end{definitions}

Next, we define the topological concepts of \emph{path} and \emph{path concatenation}, and we explain what \emph{meeting transversally once a warped disc} means, which is just a formalization of our intuition.
\begin{definitions}
(i) Let $X$ be a topological space. A \emph{path} in $X$ is a continuos map $\alpha:[a, b] \to X$, where $[a,b] \subset \R$ is a closed interval. If $\alpha$ verifies $\alpha(a) = \alpha(b) = x_0 \in \R^3$, then we say that $\alpha$ is a \emph{loop} with base point $x_0$. When this is the case, we can consider $\alpha$ as a an map whose domain is the quotient space $[a,b]/\! \sim$ obtained by identifying the end points of $[a,b]$, which is homeomorphic to $\mathbb{S}^1 := \set{(x,y): x^2+y^2=1} \subset \R^2$.

(ii) Given two paths $\alpha:[a, b] \to X$ and $\beta:[c, d] \to X$ verifying $\alpha(b) = \beta(c)$, we define the \emph{composition of paths} in the following way:
$$
\alpha * \beta: [a, b+(d-c)] \longrightarrow X,\ t \longmapsto
\left\{
\begin{array}{ll}
\alpha(t) &\text{ if } t\in[a,b],\\
\beta(t+c-b) &\text{ if } t\in[b, b+(d-c)].
\end{array}
\right.
$$

(iii) A path $\alpha:[a,b]\rightarrow\R^3$ \emph{meets transversally once the warped disc $\D_{A,\xi}$} if there exist $s_0\in(a,b)$ and $\eps>0$ such that
$$
J:=\alpha^{-1}(\D_{A,\xi}(\eps))=(s_0-\eps,s_0+\eps)
$$
is an open subinterval of $[a,b]$ and 
$$
(\zeta\circ\alpha)|_J(t)=(0,0,t-s_0),
$$
where obviously $(\zeta\circ\alpha)|_J(t) \subset \mathbb{D}_A(\eps)$ because $\alpha|_J(t) \subset \zeta^{-1}\big(\mathbb{D}_A(\eps)\big) = \D_{A,\xi}(\eps)$.

(iv) Let $C$ be a topological space homeomorphic to a closed disc and let $\phi:C\longrightarrow\R^3$ be a continuous map. The restriction $\partial\phi:=\phi|_{\partial C}$ is called the \textit{boundary map} of $\phi$. We say that the boundary map $\partial\phi$ \emph{meets transversally once a warped disc} $\D_{A,\xi}\subset\R^3$ if there exists a parameterization $\beta:[a,b]\to\partial C \cong \mathbb{S}^1$ such that the path $\alpha:=\phi\circ\beta: [a,b] \to \R^3$ meets transversally once the warped disc $\D_{A,\xi}$.

%No tengo muy claro que este bien el inglés de: "quotient space modulo the homotopy relation"
%Y convendría definir homotopía, no?
(v) Given a path-connected topological space $X$ and a point $x_0\in X$ we define the \emph{fundamental group of $X$ at the base point $x_0$} as the quotient space modulo the homotopy relation, and we denote it with $\pi_1(X,x_0)$. If $\alpha$ is a loop with base point $x_0$, then it represents an element of $\pi_1(X,x_0)$ denoted with $[\alpha]$.
\end{definitions}

\begin{remark}\label{remPath}
If the path $\alpha:[a,b]\to\R^3$ meets transversally once the warped disc $\D_{A,\xi}$, then $\alpha\big([a,b]\big)\cap\partial\D_{A,\xi}=\varnothing$. This will be helpful in Proposition \ref{propTop}.
\end{remark}
\end{subsection}
\begin{subsection}{Useful results}

\begin{lemma}\label{lemmaFundGr}
a
\end{lemma}

\begin{lemma}\label{lemmaZ}
a
\end{lemma}

\begin{lemma}\label{lemmaId}
a
\end{lemma}

\begin{proposition}\label{propTop}
a
\end{proposition}

\end{subsection}

\end{section}

\end{chapter}

\appendix
\begin{chapter}{Auxiliary definitions and results}\label{AA}

\begin{section}{Real algebraic geometry basics}
In this section we give a basic insight into the required concepts, definitions and results from real algebraic geometry. They are mostly used on the first chapter.

We begin with some definitions like \emph{real closed field} and \emph{semialgebraic set}. The \emph{Transfer Principle} allows us to move our results from $\R$ to an arbitrary real closed field $R$. We also give an overview of the \emph{Zariski topology}, in order to talk about concepts like closure or \emph{reducibility} in this topology. Finally, after defining other notions as \emph{proper maps} and \emph{germ Nash half-branch curves}, we finish the section recalling \emph{Puiseux series}, since this is the nature of the solutions of the equation $\Delta_v(x)=0$ in the first proof of Theorem \ref{openQuad}.
\begin{definition}\label{realCField}
	A \em real closed field \em is an ordered field $R$ such that $R(\sqrt{-1})$ is an algebraically closed field. There exist many characterizations of real closed fields. A very enlightening one is the following: $R$ is a real closed field if it is an ordered field that shares with the field $\R$ of real numbers its properties of the first-order language of ordered fields. 
\end{definition}

Indeed, \hyperref[tarskiSeidenberg]{Tarski-Seidenberg Theorem} admits a useful formulation in model theory that explains accurately our last sentence.

\begin{definitions}\label{semialgSet} (i) Let $R$ be a real closed field. A subset $S\subset R^n$ is \em semialgebraic \em if it is defined as a finite union of sets defined by a conjunction of polynomial equalities and inequalities: 
	\begin{equation*}
	\left\{
	\begin{aligned}
		P_1({\tt x}_1,\, .\,&.\,.\,,{\tt x}_n)=0\\
		&\vdots\\
		P_r({\tt x}_1,\, .\,&.\,.\,,{\tt x}_n)=0\\
		Q_1({\tt x}_1,\, .\,&.\,.\,,{\tt x}_n)>0 \\
		&\vdots\\
		Q_{\ell}({\tt x}_1,\, .\,&.\,.\,,{\tt x}_n)>0\\
	\end{aligned}
	\right.
	\end{equation*}
It is easily seen that finite unions and intersections of semialgebraic sets are semialgebraic sets too. In addition, the complementary set of a semialgebraic set is also a semialgebraic set. The easy proof of these facts can be studied in \cite{bcr}, Ch.2.
	
	
(ii) A map $f:S\to T$ between semialgebraic subsets $S\subset R^n$ and $T\subset R^m$ is \em semialgebraic \em if its graph is a semialgebraic subset of $R^{m+n}$.  \end{definitions}


(iii) A \em semialgebraic homeomorphism \em between two semialgebraic subsets $S\subset R^n$ and $T\subset R^m$ is a continuous and bijective semialgebraic map $f:S\to T$. It is easily seen that in such a case its inverse $f^{-1}:T\to S$ is also semialgebraic.

\begin{theorem}[\em Transfer Principle\em]\label{TP} \em Let ${\mathcal L}(R)$ be the first-order language of ordered fields with parameters in the real closed field $R$ and let $\Phi$ be a formula of ${\mathcal L}(R)$. Then, there exists a quantifier-free formula $\Psi$ of ${\mathcal L}(R)$ with the same free variables ${\tt x}_1,\dots,{\tt x}_n$ as $\Phi$ such that, for every real closed field extension $K$ of $R$ and every $x\in K^n$, the sentence $\Phi(x)$ holds true if and only if $\Psi(x)$ holds true.\em

\end{theorem}

\begin{definition}[Zariski topology]\label{zariski} (i) Let $K$ be a field. A subset $X\subset K^n$ is \em algebraic \em if it is the set of common zeros of a finite family of polynomials $f_1,\dots,f_m\in K[{\tt x}_1,\dots,{\tt x}_n]$. 

(ii) The \em Zariski topology \em of an algebraic set $X\subset K^n$ is the topology whose closed sets are the algebraic subsets of $K^n$ contained in $X$. It is indeed a topology, that is, the arbitrary intersection of algebraic sets is also an algebraic set as an straightforward consequence of Hilbert's basis theorem.

(iii) An algebraic subset $X\subset K^n$ is said to be \em reducible \em if there exist algebraic subsets $Y\subsetneq X$ and  $Z\subsetneq X$ such that $X=Y\cup Z$. If $X$ is not reducible it is said to be  \em irreducible. \em 
\end{definition}

\begin{definition}\label{pureDim} (i) Let $S\subset\R^n$ be a semialgebraic set and $p\in S$. The \em local dimension of $S$ at $p$, \em denoted $\dim(S_p)$, is the largest non-negative integer $d$ such that for every open ball $B$ centered at $p$ the intersection $S\cap B$ contains a semialgebraic subset semialgebraically homeomorphic to the cube $[0,1]^d$.

	It is said that $S$ is \em pure dimensional \em if $\dim(S_p)=\dim(S_q)$ for every pair of points $p,q\in S$.
\end{definition}

\begin{definitions}\label{properMap}
	  (i) A continuous map $f:X\to Y$ between topological spaces $X$ and $Y$ is said to be \em proper \em if $f^{-1}(K)$ is a compact subspace of $X$ for every compact subspace $K$ of $Y$. 
	  
	  (ii) A semialgebraic map $f:S\to T$ between semialgebraic sets $S\subset R^n$ and $T\subset R^m$ is said to be \em semialgebraically proper \em if $f^{-1}(K)$ is bounded and closed in $S$ for every bounded and closed in $T$ subset $K$ of $T$.  
\end{definitions}

\begin{definition}\label{dominant}
	A polynomial map $f:X\to Y$ between algebraic sets $X$ and $Y$ is said to be \em dominant \em if its image $f(X)$ is a dense subset of $Y$ in its Zariski topology. 
\end{definition}

\begin{definitions}\label{curveGerms}
	(i) A function $f:U\to\R$ defined in an open semialgebraic subset $U\subset\R^n$ is a \em Nash function \em if it is analytic and semialgebraic. 
	
	(ii) A map $f:=(f_1,\dots,f_m):U\to\R^m$ is a \em Nash map \em if each coordinate $f_i:U\to\R$ is a Nash function. 
	
	(iii) Let $\Gamma\subset\R^n$ be an algebraic curve and $p\in\Gamma$. For every small enough $\varepsilon>0$ the intersection $B_{\varepsilon}\cap\Gamma\setminus\{a\}$, % Aqui no sería p en vez de a?
where $B_{\varepsilon}\subset\R^n$ is the open ball of radius $\varepsilon$ centered at the point $p$, has finitely many connected components $C_1,\dots,C_k$. Each $C_i$ is semialgebraically homeomorphic to the interval $(0,1]$ and in fact for $i=1,\dots,k$ there exists a Nash homeomorphism  $f_i:[0,1]\to C_i\cup\{p\}$, with $f_i(0)=p$.

Indeed, this result is a particular case of the local conic structure theorem of semialgebraic sets, \cite[IX.3.6]{bcr}. 
	
Observe that, by its very definition, it makes sense to define the germs $C_{i,p}$ of $C_i$ at the point $p$ for $i=1,\dots,k$ as they are independent of the radius $\varepsilon$. These germs  $C_{i,p}$ are called the \em germ Nash half-banches \em of the curve $\Gamma$ centered at $p$. For more details see \cite[IX.5.2]{bcr}. 
\end{definitions}

\begin{definition} \label{puiseux} It is proved in \cite[pp. 98-102]{w} that given an algebraically closed field $K$ and an indeterminate ${\tt t}$ over $K$, the field $K\left(\set{{\tt t}^*}\right)$ of \em Puiseux series \em with coefficients in $K$ is algebraically closed. As it is an algebraic extension of the field $K\left({\tt t}\right)$ of rational functions over $K$, the field $K\left(\set{{\tt t}^*}\right)$ is an algebraic closure of the field $F({\tt t})$ for every subfield $F$ of $K$ such that the field extension $K|F$ is algebraic. In particular, for $F:=\R$ it follows that $\C\left(\set{{\tt t}^*}\right)$ is an algebraic closure of $\R({\tt t})$.
\end{definition}
\end{section}

\begin{section}{Root finding algorithms}
The first proof of Theorem \ref{openQuad} requires frequently to check whether a given polynomial $f$ has some root on a certain interval $I$. Sometimes we want to check that $f$ is positive or negative on $I$. To that end it suffices to evaluate it at an arbitrary point $a\in I$ and to check that $f$ has no root on $I$.

Sturm's method is used to compute the number of different real roots of a polynomial in a given interval. Note that it is an algebraic method that doesn't rely on approximations.

\begin{definitions}\label{sturmSeq} (i) Let $R$ be a real closed field and let $f\in\R[{\tt t}]$. The \emph{Sturm sequence} (or \emph{Sturm chain}) of $f$ is the finite sequence of polynomials $(f_0,f_1,\dots,f_k)$ defined as follows: 
\begin{equation*}
\begin{aligned}
f_0&:=f\\
f_1&:=f'\\
&\dots\\
f_i&:=f_{i-1}q_i-f_{i-2}, \text{ with }q_{i}\in R[{\tt x}] \text{ and } \text{deg}(f_{i})<\text{deg}(f_{i-1}) \text{ for } i=2\dots,k.\\
\end{aligned}
\end{equation*}
Then, by Euclid's Algorithm, there is an integer $k$ satisfying $f_k=\text{gcd}(f,f')$.
	
(ii) Given a sequence $(a_0, a_1, \dots, a_k)$ of elements of $R$ with $a_0 \ne 0$, we define the \emph{number of sign changes in the sequence} $(a_0, \dots, a_k)$ as follows: count one sign change every time $a_ia_{\ell} < 0$, with 
\begin{equation*}
\begin{aligned}
&\ell=i+1 \text{, or }\\
&\ell>i+1 \text{ and }a_j=0 \text{ for every } j \text{ satisfying  } i<j<\ell.\\ 
\end{aligned}
\end{equation*}

(iii) If $a\in R$ is not a root of $f$ and $(f_0,\dots,f_k)$ is the Sturm sequence of $f$, we define $v(f;a)$ to be the number of sign changes in $(f_0(a),\dots,f_k(a))$.
\end{definitions}
\begin{proposition}[Sturm's Theorem]\label{sturm} 
Let $R$ be a real closed field and $f\in R[{\tt t}]$. Let $a,b\in R$ be such that $a<b$ and neither $a$ nor $b$ are roots of $f$. Then the number of roots of $f$ in the interval $(a,b)$ equals $v(f;a)-v(f;b)$.

\em The proof of this proposition can be studied in \cite[1.2.10]{bcr}. \em
\end{proposition}

Laguerre's method differs from Sturm's method in that it is a numerical algorithm, rather than algebraic, to decide if a polynomial with real coefficients has a real root. It is remarkable that it converges to a root, with very few exceptions, from any initial value.

\begin{proposition}[Laguerre's method]\label{laguerre}
Let $f\in\R[{\tt x}]$ be a polynomial of degree $n$ and write it as
\begin{equation}\label{eq:lagPol}
f({\tt x})=({\tt x}-r)({\tt x}-q)^{n-1},
\end{equation}
where $r,q\in\C$ represent unknowns. Let 
$$
g({\tt x}):=\frac{f'({\tt x})}{f({\tt x})}=\frac{1}{{\tt x}-r}+\frac{n-1}{{\tt x}-q} \ \text{ and } \ h({\tt x}):=g^2({\tt x})-\frac{f''({\tt x})}{f({\tt x})}=\frac{1}{({\tt x}-r)^2}+\frac{n-1}{({\tt x}-q)^2}.
$$
If we solve for ${\tt x}-q$ in $g({\tt x})$ and substitute the result on $h({\tt x})$, we get a quadratic equation for ${\tt x}-r$, whose solution is named \em Laguerre's formula\em:
\begin{equation}\label{eq:lagEq}
{\tt x}-r=n\left(g({\tt x})\pm\sqrt{(n-1)(nh({\tt x})-g^2({\tt x}))}\right)^{-1}.
\end{equation}

Equation \em \ref{eq:lagEq} \em defines a numerical method by choosing on each step the sign that results in the larger magnitude of the denominator and taking the new root to be:
$$
x_{k+1}=x_k-n\left(g(x_k)\pm\sqrt{ (n-1)(nh(x_k)-g^2(x_k))}\right)^{-1}.
$$
Furthermore, this iterative formula works with any polynomial, not just with the ones described by equation \em \ref{eq:lagPol}. \em 
\end{proposition}

{\bf El algoritmo, tal y como se describe, parece fuertemente ligado al hecho de que $f$ tenga una ra\'iz, tal vez compleja, de multiplicidad $n-1$. Por eso no entiendo qu\'e significa que la f\'ormula funciona para polinomios cualesquiera!!!}


\end{section}
\end{chapter}

\begin{chapter}{Sage code}

\end{chapter}

\begin{chapter}{Python code}

\end{chapter}

\begin{thebibliography}{ABR}

\bibitem[ABR]{abr} C. Andradas, L. Br\"ocker, J.M. Ruiz: Constructible 
sets in real geometry. \em Ergeb. Math. \em{\bf 33}. Berlin, Heidelberg, 
New York: Springer Verlag, (1996).

\bibitem[BCR]{bcr} J. Bochnak, M. Coste, M.-F. Roy: G\'eom\'etrie
alg\'ebrique r\'eelle. \em Ergeb. Math. \em {\bf 12}, Springer-Verlag,
Berlin, Heidelberg, New York (1987).

\bibitem[FG]{fg} J.F. Fernando, J.M. Gamboa: Polynomial images of $R^n$.
\textit{Journal of Pure and Applied Algebra}, {\bf 179}, (2003), no. 3, 241-254.

\bibitem[FGU]{fgu} J.F. Fernando, J.M. Gamboa, C. Ueno: The open quadrant problem:
A topological proof. \textit{Preprint} (2015), 13 pages.

\bibitem[FU]{fu} J.F. Fernando, C. Ueno: A short proof for the open quadrant problem.
\textit{Preprint RAAG} (2014, submitted to MEGA 2015), 8 pages.

\bibitem[G]{g} J.M. Gamboa: Algebraic images of the real plane. \textit{Reelle algebraische Geometrie}, June,
$10^{\text{th}}-16^{\text{th}}$ (1990), Oberwolfach.

\bibitem[U]{u} C. Ueno: Im\'agenes polin\'omicas y regulares de espacios eucl\'\i deos. {\em Ph.D. Thesis UCM} (2012).

\bibitem[W]{w} R.J. Walker: \em Algebraic curves. \em Berlin, Heidelberg, 
New York: Springer Verlag, (1978).



\end{thebibliography}


\end{document}
